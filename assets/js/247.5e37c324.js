(window.webpackJsonp=window.webpackJsonp||[]).push([[247],{547:function(_,t,a){"use strict";a.r(t);var v=a(25),r=Object(v.a)({},(function(){var _=this,t=_._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[t("ul",[t("li",[t("a",{attrs:{href:"#1-%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"}},[_._v("1. 人工神经网络")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#%E7%A5%9E%E7%BB%8F%E5%85%83%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%84%9F%E7%9F%A5%E5%99%A8%E7%AE%97%E6%B3%95"}},[_._v("神经元模型和感知器算法")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#11-%E6%84%9F%E7%9F%A5%E5%99%A8%E7%AE%97%E6%B3%95%E8%AF%81%E6%98%8E"}},[_._v("1.1. 感知器算法证明")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#12-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%86%AC%E5%A4%A9"}},[_._v("1.2. 人工智能的第一次冬天")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#13-%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"}},[_._v("1.3. 多层神经网络")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#16-%E5%90%8E%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95back-propogation-algorithm"}},[_._v("1.6. 后向传播算法（Back Propogation Algorithm）")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#17-bp%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC"}},[_._v("1.7. BP算法推导")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#18-bp%E4%B8%80%E8%88%AC%E6%80%A7%E6%8E%A8%E5%AF%BC"}},[_._v("1.8. BP一般性推导")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#110-%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BC%98%E5%8A%A3%E5%8A%BF"}},[_._v("1.10. 多层神经网络的优劣势")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#111-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"}},[_._v("1.11. 随机梯度下降")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#112-%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E5%88%9D%E5%A7%8B%E5%8C%96"}},[_._v("1.12. 训练数据初始化")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#113-w-b%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96"}},[_._v("1.13. (W, b)的初始化")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#114-batch-normalization"}},[_._v("1.14. Batch Normalization")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#115-%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E9%80%89%E6%8B%A9"}},[_._v("1.15. 目标函数选择")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#116-%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5"}},[_._v("1.16. 参数更新策略")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#1161-%E5%B8%B8%E8%A7%84%E7%9A%84%E6%9B%B4%E6%96%B0-vanilla-stochastic-gradient-descent"}},[_._v("1.16.1. 常规的更新 （Vanilla Stochastic Gradient Descent）")])])])]),_._v(" "),t("li",[t("a",{attrs:{href:"#117-%E8%AE%AD%E7%BB%83%E5%BB%BA%E8%AE%AE"}},[_._v("1.17. 训练建议")])])])])]),_._v(" "),t("h2",{attrs:{id:"_1-人工神经网络"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-人工神经网络"}},[_._v("#")]),_._v(" 1. 人工神经网络")]),_._v(" "),t("h3",{attrs:{id:"神经元模型和感知器算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#神经元模型和感知器算法"}},[_._v("#")]),_._v(" 神经元模型和感知器算法")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530121045_cd977e06b33f.png",alt:"img"}})]),_._v(" "),t("p",[_._v("感知器算法和SVM的本质区别："),t("strong",[_._v("感知器算法是思路是一个一个样本的看，如果对就不管它，如果不对更新W和b")]),_._v("，SVM的思路是将样本集视为整体。\n感知器很像我们日常生活，"),t("strong",[_._v("比如考试经常考第一，就不去调整，如果语文没考好，就要调整学习语文的方法")]),_._v("。SVM算法是全局，"),t("strong",[_._v("感知器算法是针对每一个个体去调整")]),_._v("。")]),_._v(" "),t("p",[_._v("1957年，Frank Rosenblatt从纯数学的度重新考察这一模型，指出能够从一些输入输出对(X, y)中通过学习算法获得权重W和b。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530113822_84a41975b152.png",alt:"img"}})]),_._v(" "),t("p",[_._v("算法本质是：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530113753_faf1b98fea05.png",alt:"img"}})]),_._v(" "),t("h3",{attrs:{id:"_1-1-感知器算法证明"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-感知器算法证明"}},[_._v("#")]),_._v(" 1.1. 感知器算法证明")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530115752_7e648f0dbd1e.png",alt:"img"}})]),_._v(" "),t("p",[_._v("那么原来的算法可以改成：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530120223_3dee4390e05a.png",alt:"img"}})]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530115813_b1f73645a336.png",alt:"img"}})]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530120557_dcd9607ad399.png",alt:"img"}})]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530120641_457faca9ff1b.png",alt:"img"}})]),_._v(" "),t("h3",{attrs:{id:"_1-2-人工智能的第一次冬天"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-人工智能的第一次冬天"}},[_._v("#")]),_._v(" 1.2. 人工智能的第一次冬天")]),_._v(" "),t("p",[_._v("Minsky第一次提出了线性可分（不可分）的概念。1969年《Perceptron》。日常生活中有很多分类问题是非线性可分的。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530122245_47e7de087bdb.png",alt:"img"}})]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530122726_b7a9f5da8e2c.png",alt:"img"}})]),_._v(" "),t("p",[_._v("这本书的出现，使人们意识到感知器的算法是如此狭窄，使得人工智能项目的经费都批不下来。十年左右的停滞。")]),_._v(" "),t("h3",{attrs:{id:"_1-3-多层神经网络"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-多层神经网络"}},[_._v("#")]),_._v(" 1.3. 多层神经网络")]),_._v(" "),t("p",[_._v("第二次复兴："),t("strong",[_._v("用非线性的函数集合（模型）去区分非线性的样本")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530155101_6916b1b885b7.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("φ(*)是非线性函数")]),_._v("，因为若不是的话，和上面的单层网络没有任何区别。")]),_._v(" "),t("p",[_._v("定理："),t("strong",[_._v("当φ(*)为阶跃函数时，三层网络可以模拟任意决策面")]),_._v("。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530155434_9a36491cdce8.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("阶跃函数就是大于0的地方等于1，让小于0的地方等于1")]),_._v("。")]),_._v(" "),t("p",[_._v("举例：两层神经网络模拟一个非线性决策面，最后"),t("strong",[_._v("W取[1,1,1], b取-2.5")]),_._v("：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530160204_1eec8e098901.png",alt:"img"}})]),_._v(" "),t("p",[_._v("如果决策面是四边形，第二层神经元就有4个，最后"),t("strong",[_._v("W取[1,1,1,1], b取-3.5")]),_._v("。")]),_._v(" "),t("p",[_._v("如果决策面是圆的话，第二层就有"),t("strong",[_._v("无穷多个神经元，去逼近圆")]),_._v("。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530161130_c3d472f9647a.png",alt:"img"}})]),_._v(" "),t("p",[_._v("如果决策面分开了，"),t("strong",[_._v("要在第二层里把神经元竖着写下去")]),_._v("，并且加一层神经元，把他们的结果合并起来。")]),_._v(" "),t("p",[_._v("对于两个三角形的情况，最后"),t("strong",[_._v("W取[1,1], b取-0.5")]),_._v("。只要有一个1，最后结果就是1；都是0，最后结果就是0。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530161033_29588e9d48ca.png",alt:"img"}})]),_._v(" "),t("p",[_._v("神经网络理论并不完备，对于某类问题适合什么样的模型并没有答案，只能用实验的方法。")]),_._v(" "),t("h3",{attrs:{id:"_1-6-后向传播算法-back-propogation-algorithm"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-后向传播算法-back-propogation-algorithm"}},[_._v("#")]),_._v(" 1.6. 后向传播算法（Back Propogation Algorithm）")]),_._v(" "),t("p",[_._v("梯度下降法求局部极值（Gradient Descent Method）。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530164030_1f323ed65992.png",alt:"img"}})]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530164235_105f1386509b.png",alt:"img"}})]),_._v(" "),t("p",[_._v("中间的式子中，α大于0，所以f(wk+1) <f(wk)")]),_._v(" "),t("ul",[t("li",[_._v("梯度下降法就是不断试探的过程。")]),_._v(" "),t("li",[_._v("和初始值的选择有很大的关系。")])]),_._v(" "),t("p",[_._v("先找到一个下降的方向，然后再想具体怎么走。所以梯度下降法有很多变种。"),t("strong",[_._v("梯度下降法只负责找一个方向")]),_._v("。")]),_._v(" "),t("h3",{attrs:{id:"_1-7-bp算法推导"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-7-bp算法推导"}},[_._v("#")]),_._v(" 1.7. BP算法推导")]),_._v(" "),t("p",[_._v("先从一个简化版本入手：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530173143_1de34e810355.png",alt:"img"}})]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530173201_57aca6c31bec.png",alt:"img"}})]),_._v(" "),t("p",[_._v("和上面公式的不同是，上面是一维的，用d，这里是多维的，所以用偏导。")]),_._v(" "),t("p",[_._v("每输入一个X，求一次W和b，直到全部输完。")]),_._v(" "),t("p",[t("strong",[_._v("先算y、a1、a2的偏导，因为这三个点连接关系最丰富")]),_._v("。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530173410_bde402118272.png",alt:"img"}})]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530173841_cf87002b5654.png",alt:"img"}})]),_._v(" "),t("p",[_._v("为什么叫后向传播算法？输入一个X，首先进行前向计算，得到y、z、a等，然后计算偏导，"),t("strong",[_._v("计算偏导的时候是从后面算到前面")]),_._v("，即y、a1、a2直到w等。")]),_._v(" "),t("p",[_._v("常见的非线性函数：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530172814_a687d84443fc.png",alt:"img"}})]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530172839_7a5570efd646.png",alt:"img"}})]),_._v(" "),t("p",[_._v("要让后向传播算法能够进行，必须"),t("strong",[_._v("改造φ(x)")]),_._v("，因为阶跃函数的φ'(x)在除了x=0的时候都等于0，这显然不合适。比如改造成"),t("strong",[_._v("sigmod函数")]),_._v("。"),t("strong",[t("code",[_._v("φ'(x) = φ(x)*(1-φ(x))")])])]),_._v(" "),t("p",[t("strong",[_._v("将sigmoid函数或者tanh函数替换阶跃函数，也能用三层网络模拟任何决策面")]),_._v("。")]),_._v(" "),t("p",[_._v("sigmoid函数和tanh函数的问题在于，"),t("strong",[_._v("当x特别大的时候，y被压制了，导致信息无法从这一层传导到下一层。而Relu函数可以")]),_._v("。第四种被称为"),t("strong",[_._v("Leak Relu")]),_._v("函数，"),t("strong",[_._v("当x < 0时，用较小的斜率压缩，而不是都将其变为0")]),_._v(".")]),_._v(" "),t("h3",{attrs:{id:"_1-8-bp一般性推导"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-8-bp一般性推导"}},[_._v("#")]),_._v(" 1.8. BP一般性推导")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530220509_7adbb9a23fd3.png",alt:"img"}})]),_._v(" "),t("p",[_._v("BP流程：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530220542_ac4f00e62f33.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("某一层W是m*n，就是m个神经元，b和z的维度都是m，和神经元个数一致")]),_._v("。")]),_._v(" "),t("p",[_._v("求偏E/偏Zi，需要先求偏E/偏ai，然后乘以偏ai/偏Zi，因为Zi并不和E直接相连，它们通过ai连接。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530222525_33403d4d2e2b.png",alt:"img"}})]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530222547_e42de5825331.png",alt:"img"}})]),_._v(" "),t("p",[_._v("i，j容易混淆，就是定义W的时候[[w11, w12, w13, ...], [w21, w22, w23], ...]")]),_._v(" "),t("h3",{attrs:{id:"_1-10-多层神经网络的优劣势"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-10-多层神经网络的优劣势"}},[_._v("#")]),_._v(" 1.10. 多层神经网络的优劣势")]),_._v(" "),t("p",[_._v("优势：")]),_._v(" "),t("ol",[t("li",[t("strong",[_._v("基本单元简单，多个基本单元可扩展为非常复杂的非线性函数。因此易于构建，同时模型有很强的表达能力")]),_._v("。")]),_._v(" "),t("li",[_._v("训练和测试的计算并行性非常好，有利于在"),t("strong",[_._v("分布式系统")]),_._v("上的应用。")]),_._v(" "),t("li",[t("strong",[_._v("模型构建来源于对人脑的仿生，话题丰富")]),_._v("，各种领域的研究人员都有兴趣，都能做贡献。")])]),_._v(" "),t("p",[_._v("劣势：")]),_._v(" "),t("ol",[t("li",[_._v("数学不漂亮，"),t("strong",[_._v("优化算法只能获得局部极值，算法性能与初始值有关")]),_._v("。")]),_._v(" "),t("li",[t("strong",[_._v("不可解释。训练神经网络获得的参数与实际任务的关联性非常模糊")]),_._v("。")]),_._v(" "),t("li",[t("strong",[_._v("模型可调整的参数很多")]),_._v(" （网络层数、每层神经元个数、非线性函数、学习率、优化方法、终止条件等等），使得训练神经网络变成了一门“艺术”。")]),_._v(" "),t("li",[_._v("如果要训练相对复杂的网络，需要"),t("strong",[_._v("大量的训练样本")]),_._v("。")])]),_._v(" "),t("h3",{attrs:{id:"_1-11-随机梯度下降"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-11-随机梯度下降"}},[_._v("#")]),_._v(" 1.11. 随机梯度下降")]),_._v(" "),t("ol",[t("li",[_._v("（"),t("strong",[_._v("不用每输入一个样本就去变换参数，而是输入一批样本")]),_._v("（叫做一个"),t("code",[_._v("BATCH")]),_._v("或"),t("code",[_._v("MINI-BATCH")]),_._v("），"),t("strong",[_._v("求出这些样本的梯度平均值后，根据这个平均值改变参数")]),_._v("。")]),_._v(" "),t("li",[_._v("在神经网络训练中，BATCH的样本数大致设置为50-200不等。")])]),_._v(" "),t("p",[_._v("随机梯度下降的好处，"),t("strong",[_._v("降低随机性")]),_._v("，同时"),t("strong",[_._v("不要让参数进行太剧烈的变化，即通过平均值改变，可以降低噪声的影响")]),_._v("。")]),_._v(" "),t("h3",{attrs:{id:"_1-12-训练数据初始化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-12-训练数据初始化"}},[_._v("#")]),_._v(" 1.12. 训练数据初始化")]),_._v(" "),t("p",[_._v("做均值和方差归一化。目的："),t("strong",[_._v("使输入的特征每一个维度对后面的影响都差不多。")])]),_._v(" "),t("h3",{attrs:{id:"_1-13-w-b-的初始化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-13-w-b-的初始化"}},[_._v("#")]),_._v(" 1.13. (W, b)的初始化")]),_._v(" "),t("p",[t("strong",[_._v("梯度消失")]),_._v("现象：如"),t("strong",[_._v("果W"),t("sup",[_._v("T")]),_._v("+b一开始很大或很小，那么梯度将趋近于0")]),_._v("，反向传播后前面与之相关的梯度也趋近于0，导致"),t("strong",[_._v("训练缓慢")]),_._v("。 因此，我们要使y=±1一开始在零附近。")]),_._v(" "),t("p",[_._v("W和b的初始化问题，最近很火，有很多相关文章")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530232832_ab3a49394bff.png",alt:"img"}})]),_._v(" "),t("h3",{attrs:{id:"_1-14-batch-normalization"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-14-batch-normalization"}},[_._v("#")]),_._v(" 1.14. Batch Normalization")]),_._v(" "),t("p",[_._v("google论文：Batch normalization accelerating deep network training by reducing internal covariate shift (2015)")]),_._v(" "),t("p",[_._v("基本思想："),t("strong",[_._v("既然我们希望每一层获得的值都在0附近，从而避免梯度消失现象，那么我们为什么不直接把每一层的值做基于均值和方差的归一化呢")]),_._v("？")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530234729_c3e58bada0db.png",alt:"img"}})]),_._v(" "),t("p",[_._v("batch normalization中的均值和方差，是在不断输入样本中累积和记录的。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530234816_a01ffe74d06b.png",alt:"img"}})]),_._v(" "),t("p",[_._v("和上面一样，"),t("strong",[_._v("值不能都集中在0附近，否则就变成了线性模型，没有充分利用其非线性的性质，以至于分类效果不佳")]),_._v("。因此不能就只是归一化这样结束，"),t("strong",[_._v("还要用β和γ，将它放缩掉。β和γ作为训练的参数")]),_._v("。")]),_._v(" "),t("h3",{attrs:{id:"_1-15-目标函数选择"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-15-目标函数选择"}},[_._v("#")]),_._v(" 1.15. 目标函数选择")]),_._v(" "),t("p",[_._v("1、加关于W的正则，原因：W不应该很大，否则输入输出会很大，从而不可控。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200530235007_18e3f9c0568b.png",alt:"img"}})]),_._v(" "),t("p",[_._v("2、如果是分类问题，F(W)可以采用SOFTMAX函数和交叉熵的组合。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531095021_74cc3f775da8.png",alt:"img"}})]),_._v(" "),t("p",[_._v("如果F(W)是SOFTMAX函数和交叉熵的组合，那么求导将会有非常简单的形式：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531095106_ed1e9a66b9b0.png",alt:"img"}})]),_._v(" "),t("p",[_._v("最后输出的时候，"),t("strong",[_._v("强行用softmax变成概率")]),_._v("。比如"),t("strong",[_._v("猫狗分类问题，有可能有个样本60%像猫，40%像狗")]),_._v("。softmax在图像识别中特别常见。")]),_._v(" "),t("p",[_._v("交叉熵中，可以通过Jensen不等式证明，"),t("strong",[_._v("如果所有的p和为1，所有的q和为1，那么E一定大于0")]),_._v("。并且"),t("strong",[_._v("如果q和p越像，那么E越小")]),_._v("。")]),_._v(" "),t("p",[_._v("之前求E的方法，称为"),t("code",[_._v("Mean Squared Error")]),_._v(" (均方误差)")]),_._v(" "),t("h3",{attrs:{id:"_1-16-参数更新策略"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-16-参数更新策略"}},[_._v("#")]),_._v(" 1.16. 参数更新策略")]),_._v(" "),t("h4",{attrs:{id:"_1-16-1-常规的更新-vanilla-stochastic-gradient-descent"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-16-1-常规的更新-vanilla-stochastic-gradient-descent"}},[_._v("#")]),_._v(" 1.16.1. 常规的更新 （Vanilla Stochastic Gradient Descent）")]),_._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[_._v("nn.W{k} = nn.W{k} - nn.learning_rate*nn.W_grad{k};\nnn.b{k} = nn.b{k} - nn.learning_rate*nn.b_grad{k};\n")])])]),t("p",[_._v("SGD的问题")]),_._v(" "),t("p",[_._v("（1）(W,b)的"),t("strong",[_._v("每一个分量获得的梯度绝对值有大有小")]),_._v("，一些情况下，"),t("strong",[_._v("将会迫使优化路径变成Z字形状")]),_._v("。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531102515_214c497dfaa1.png",alt:"img"}})]),_._v(" "),t("p",[_._v("上图中的线可视为等高线，E相等的线，一个方向gradient很大，另一个方向很小。梯度的分量有的特别大，有的特别小的时候，优化的路径不是特别好。")]),_._v(" "),t("p",[_._v("（2）SGD求梯度的策略过于随机，"),t("strong",[_._v("由于上一次和下一次用的是完全不同的BATCH数据，将会出现优化的方向随机的情况")]),_._v("。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531102633_f379d94bb278.png",alt:"img"}})]),_._v(" "),t("p",[_._v("解决各个方向梯度不一致的方法：")]),_._v(" "),t("p",[t("strong",[_._v("（1）AdaGrad")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531102802_d74d3f179edc.png",alt:"img"}})]),_._v(" "),t("p",[_._v("AdaGrad："),t("strong",[_._v("如果某一个方向上的梯度的绝对值特别大或特别小，就除以这个梯度的绝对值")]),_._v("，使得梯度绝对值高的步长不要太大，梯度绝对值低的步长不要太小。")]),_._v(" "),t("p",[_._v("不仅如此，"),t("strong",[_._v("它不只算了某一个batch里的梯度，还做了叠加。从而越到后面梯度和r越来越大，步长越来越小，而开始时很大")]),_._v("。")]),_._v(" "),t("p",[t("strong",[_._v("（2）RMSProp")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531102917_7cc247594f30.png",alt:"img"}})]),_._v(" "),t("p",[_._v("RMSProp："),t("strong",[_._v("给以前的累积梯度r和现在的梯度加一个权重ρ，二者权重之和为1，之前等于是各0.5")]),_._v("。用此权重平衡更看重谁。")]),_._v(" "),t("p",[t("strong",[_._v("（3）Momentum")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531103038_b7a9a641c013.png",alt:"img"}})]),_._v(" "),t("p",[_._v("Momentum："),t("strong",[_._v("第一次算出来的方向对第二次还有一点点影响")]),_._v("。")]),_._v(" "),t("p",[t("strong",[_._v("（4）Adam")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531103222_5373fce65c07.png",alt:"img"}})]),_._v(" "),t("p",[_._v("Adam：综合以上方法，让"),t("strong",[_._v("梯度各个方向差不多，同时让梯度下降方向相对平滑")]),_._v("。"),t("strong",[_._v("ρ1：0.9，ρ2：0.999")]),_._v("。结果证明并不好用。")]),_._v(" "),t("h3",{attrs:{id:"_1-17-训练建议"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-17-训练建议"}},[_._v("#")]),_._v(" 1.17. 训练建议")]),_._v(" "),t("ol",[t("li",[_._v("一般情况下，在训练集上的目标函数的平均值（cost，就是上面提到的E）会随着训练的深入而不断减小，如果这个指标有增大情况，停下来。有两种情况："),t("strong",[_._v("第一是采用的模型不够复杂，以致于不能在训练集上完全拟合；第二是已经训练很好了")]),_._v("。")]),_._v(" "),t("li",[t("strong",[_._v("分出一些验证集（Validation Set）")]),_._v(",训练的本质目标是在验证集上获取最大的识别率。因此训练一段时间后，必须在验证集上测试识别率，保存使验证集上识别率最大的模型参数，作为最后结果。")]),_._v(" "),t("li",[_._v("注意"),t("strong",[_._v("调整学习率（Learning Rate）")]),_._v(","),t("strong",[_._v("如果刚训练几步cost就增加，一般来说是学习率太高了；如果每次cost变化很小，说明学习率太低。")])]),_._v(" "),t("li",[t("strong",[_._v("Batch Normalization")]),_._v(" 比较好用，用了这个后，对学习率、参数更新策略等不敏感。建议如果用Batch Normalization, 更新策略用最简单的SGD即可，我的经验是加上其他反而不好。")]),_._v(" "),t("li",[_._v("如果不用Batch Normalization, 我的经验是，合理变换其他参数组合，也可以达到目的。")]),_._v(" "),t("li",[_._v("由于梯度累积效应，"),t("strong",[_._v("AdaGrad, RMSProp, Adam")]),_._v("三种更新策略"),t("strong",[_._v("到了训练的后期会很慢")]),_._v("，可以采用提高学习率的策略来补偿这一效应。")])]),_._v(" "),t("p",[_._v("第二条的原因是："),t("strong",[_._v("过拟合，尽信书不如无书")]),_._v("。"),t("strong",[_._v("在训练集上效果很好，但在测试集上效果不好，就是书呆子")]),_._v("。")]),_._v(" "),t("p",[_._v("要调的最重要的一个参数是学习率。")])])}),[],!1,null,null,null);t.default=r.exports}}]);