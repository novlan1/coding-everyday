(window.webpackJsonp=window.webpackJsonp||[]).push([[252],{522:function(_,t,v){"use strict";v.r(t);var e=v(14),a=Object(e.a)({},(function(){var _=this,t=_._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[t("ul",[t("li",[t("a",{attrs:{href:"#1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"}},[_._v("1. 深度学习")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#11-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%87%86%E5%A4%87"}},[_._v("1.1. 数据库准备")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#111-mnist%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E6%95%B0%E6%8D%AE%E5%BA%93-lecun-%E5%9C%A81998%E5%B9%B4%E5%88%9B%E9%80%A0lenet%E4%BD%9C%E8%80%85"}},[_._v("1.1.1. Mnist:手写数字数据库 （LeCun 在1998年创造，LeNet作者）")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#112-imagenetfei-fei-li%E7%AD%89-2007%E5%B9%B4%E5%88%9B%E9%80%A0"}},[_._v("1.1.2. ImageNet:（Fei-fei Li等 2007年创造）")])])])]),_._v(" "),t("li",[t("a",{attrs:{href:"#12-%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8"}},[_._v("1.2. 自编码器")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#13-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"}},[_._v("1.3. 卷积神经网络")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#14-alexnet"}},[_._v("1.4. AlexNet")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#15-alexnet-%E6%94%B9%E8%BF%9B"}},[_._v("1.5. AlexNet 改进")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#16-caffe%E7%9A%84%E4%BC%98%E5%8A%A3"}},[_._v("1.6. Caffe的优劣")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#17-%E8%BF%91%E5%B9%B4%E6%9D%A5%E6%B5%81%E8%A1%8C%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"}},[_._v("1.7. 近年来流行的网络结构")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#171-vggnet-simonyan-and-zisserman-2014"}},[_._v("1.7.1. VGGNet: （Simonyan and Zisserman, 2014）")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#172-googlenet-szegedy-2014"}},[_._v("1.7.2. GoogLeNet: （Szegedy, 2014）")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#173-resnet-he-et-al-2015"}},[_._v("1.7.3. ResNet: （He et al, 2015）")])])])]),_._v(" "),t("li",[t("a",{attrs:{href:"#18-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%BA%94%E7%94%A8"}},[_._v("1.8. 卷积神经网络的应用")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#19-transfer-learning%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"}},[_._v("1.9. Transfer Learning迁移学习")])])])])]),_._v(" "),t("h2",{attrs:{id:"_1-深度学习"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-深度学习"}},[_._v("#")]),_._v(" 1. 深度学习")]),_._v(" "),t("h3",{attrs:{id:"_1-1-数据库准备"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-数据库准备"}},[_._v("#")]),_._v(" 1.1. 数据库准备")]),_._v(" "),t("h4",{attrs:{id:"_1-1-1-mnist-手写数字数据库-lecun-在1998年创造-lenet作者"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-1-mnist-手写数字数据库-lecun-在1998年创造-lenet作者"}},[_._v("#")]),_._v(" 1.1.1. Mnist:手写数字数据库 （LeCun 在1998年创造，LeNet作者）")]),_._v(" "),t("ol",[t("li",[_._v("手写数字 0-9共10类")]),_._v(" "),t("li",[_._v("训练样本60000个，测试样本10000个。")]),_._v(" "),t("li",[_._v("图像大小 28*28 二值图像。")]),_._v(" "),t("li",[_._v("样例：")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531105253_e99e22b7a7c0.png",alt:"img"}})]),_._v(" "),t("h4",{attrs:{id:"_1-1-2-imagenet-fei-fei-li等-2007年创造"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-2-imagenet-fei-fei-li等-2007年创造"}},[_._v("#")]),_._v(" 1.1.2. ImageNet:（Fei-fei Li等 2007年创造）")]),_._v(" "),t("ol",[t("li",[_._v("1000类，100多万张（2009年的规模）")]),_._v(" "),t("li",[_._v("图片大小：正常图片大小，像素几百*几百")]),_._v(" "),t("li",[_._v("WORDNET结构，拥有多个Node（节点）。一个node（目前）含有至少500个对应物体的可供训练的图片/图像。（比如先分成动物大类，再分成猫和狗）")])]),_._v(" "),t("h3",{attrs:{id:"_1-2-自编码器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-自编码器"}},[_._v("#")]),_._v(" 1.2. 自编码器")]),_._v(" "),t("p",[_._v("多层神经网络出来以后，只火了一小会。上世纪90年代到2006年，叫"),t("strong",[_._v("人工神经网络的沉寂期")]),_._v("。")]),_._v(" "),t("p",[_._v("原因，1："),t("strong",[_._v("人工神经网络在小样本集上比SVM优势不明显，甚至没有优势")]),_._v("，2：SVM理论漂亮，人工神经网络"),t("strong",[_._v("数学理论不够漂亮")]),_._v("。")]),_._v(" "),t("p",[_._v("经常称人工神经网络为启发性的方法，即完全没有道理，没有理论性的方法。Heuristic Method。")]),_._v(" "),t("p",[_._v("深度学习三剑客的坚持：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531110410_fe68f2375075.png",alt:"img"}})]),_._v(" "),t("blockquote",[t("p",[_._v("LeCun:“这种算法很有价值，不知为什么要放弃它。”\nHinton: “智能产生于人脑，所以从长远来说，人工智能应该像大脑系统一样工作。”")])]),_._v(" "),t("p",[_._v("这三人从2003年开始，一起组成了“Deep learning conspiracy”,悄悄开发了10层以上的人工神经网络。")]),_._v(" "),t("p",[_._v("2006年是深度学习的起始年，"),t("strong",[_._v("Hinton")]),_._v("在SCIENCE上发文，提出一种叫做自动编码机（Auto-encoder）的方法，部分解决了神经网络参数初始化的问题。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531114458_5ad86272438a.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("训练X到X，然后删掉最后的X（只保留编码器部分）")]),_._v("，并且在训练的时候保持第一层不要动，相当于"),t("strong",[_._v("特征提取器")]),_._v("。实际上把X的信息压缩。训练好第M-1层后，接着训练第M层，然后"),t("strong",[_._v("固定前M-1层参数不动")]),_._v("。")]),_._v(" "),t("p",[t("strong",[_._v("one-hot vector")]),_._v(", 最后一层神经元个数是label个数，"),t("strong",[_._v("比如有10类，最后一层就有十个")]),_._v("，即"),t("strong",[_._v("输出维度为10维")]),_._v("。几乎是神经网络做识别问题的标准配置，而"),t("strong",[_._v("不是最后输出一个数1或0这种")]),_._v("。")]),_._v(" "),t("h3",{attrs:{id:"_1-3-卷积神经网络"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-卷积神经网络"}},[_._v("#")]),_._v(" 1.3. 卷积神经网络")]),_._v(" "),t("p",[_._v("卷积神经网络(Convolutional Neural Network, CNN)由LeCun在上世纪90年代提出。")]),_._v(" "),t("p",[_._v("LeCun Y., Bottou L., Bengio Y., and Haffner P., Gradient-based learning applied to document recognition, Proceedings of the IEEE, pp. 1-7, 1998.")]),_._v(" "),t("p",[t("strong",[_._v("卷积核和傅里叶变换、小波变换等一样，都是乘起来，再加起来")]),_._v("。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531143949_846ea7588dca.png",alt:"img"}})]),_._v(" "),t("p",[_._v("卷积神经网络用一句话描述就是："),t("strong",[_._v("由手工设计卷积核，变成自动学习卷积核")]),_._v("。")]),_._v(" "),t("p",[_._v("相关概念")]),_._v(" "),t("ul",[t("li",[_._v("原图像和卷积核都有："),t("strong",[_._v("width、heght、channel")]),_._v("，如果是视频的话，还有第四维（时间）。")]),_._v(" "),t("li",[t("strong",[_._v("步长stride")]),_._v("，是每次移动多少，包括width、height两维。")]),_._v(" "),t("li",[_._v("卷积核和原来的图像卷积后的结果称为"),t("strong",[_._v("特征图")]),_._v("（"),t("strong",[_._v("feature map")]),_._v("）。")])]),_._v(" "),t("p",[_._v("图像大小：（M，N）；卷积核大小：（m，n）；步长：（u，v）；求特征图大小（K，L）数值？")]),_._v(" "),t("ul",[t("li",[_._v("点1：1~m；")]),_._v(" "),t("li",[_._v("点2：(1+u)~m+u；")]),_._v(" "),t("li",[_._v("点K：**(1+(K-1)"),t("em",[_._v("u) ~ m + (K-1)"),t("em",[_._v("u")])])]),_._v(" "),t("li",[_._v("所以 "),t("strong",[_._v("k <= (M-m)/u+1")]),_._v("，同理"),t("strong",[_._v("L <= (N-n)/v+1")])])]),_._v(" "),t("p",[t("strong",[_._v("zero-padding")]),_._v("或者"),t("strong",[_._v("padding")]),_._v("：补零策略，"),t("strong",[_._v("在stride较大，漏掉了图像的边缘的部分时候使用")]),_._v("。比如"),t("code",[_._v("5*5")]),_._v("的图像，"),t("code",[_._v("2*2")]),_._v("的卷积核，stride是2，那么m每个维度需要补一个0.")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531144111_53c3700a9645.png",alt:"img"}})]),_._v(" "),t("p",[_._v("第一层卷积要学习的参数个数有"),t("code",[_._v("5*5*3*6=75*6=450")]),_._v("个，即"),t("strong",[_._v("6个卷积核")]),_._v("。如果每个卷积核"),t("strong",[_._v("自带一个偏置")]),_._v("的话，"),t("strong",[_._v("要学习的参数个数就是"),t("code",[_._v("（5*5*3 + 1）*6")]),_._v("=456")])]),_._v(" "),t("p",[t("strong",[_._v("如果我们用6个卷积核，就能获得6个特征图（feature map）")]),_._v("。"),t("strong",[_._v("你也可以把产生的6个特征图看成一个新的“图像”")]),_._v("，其height, width, channel数目分别是28,28,6。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531144220_f856fb75f460.png",alt:"img"}})]),_._v(" "),t("p",[_._v("等价于：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531144231_8d154f4233d8.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("卷积神经网络和多层神经网络没有太大区别，可以将图像卷积看成全连接网络的权值共享（weight sharing）")]),_._v("，同时有一些ω等于0。"),t("strong",[_._v("其唯一本质区别就是共享了权重，比如x1、x2、x4、x5共用了ω1。")])]),_._v(" "),t("p",[_._v("LeNet-5网络结构如下图所示：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531144326_2b4d1fa953ea.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("做完第一层卷积后，都要做一层非线性变换，比如sigmoid、relu、tanh")]),_._v("。然后降采样"),t("strong",[_._v("subsampling")]),_._v("，每"),t("code",[_._v("2*2")]),_._v("个格子，取平均值，从而"),t("code",[_._v("28*28=>14*14")]),_._v("。")]),_._v(" "),t("p",[t("strong",[_._v("每做完一层卷积、降采样、全连接后，都要接一层非线性变换，否则两个线性变换层直接相连，就和一层线性变换没什么区别")]),_._v("。")]),_._v(" "),t("p",[t("strong",[_._v("降采样后向传播中梯度怎么处理？乘以1/4，分配到每个格子")]),_._v("。")]),_._v(" "),t("p",[t("strong",[_._v("全连接层")]),_._v("：本例中，"),t("strong",[t("code",[_._v("16*5*5")]),_._v("共400个神经元要和下一层的120个神经元，每个都要连起来，参数个数共有"),t("code",[_._v("(400+1)*120")])]),_._v("。1是偏置，每次前面的数过来都带个偏置，就像改嫁的女人带个孩子。")]),_._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[_._v("参数个数计算：\n\n第1层(convolutional layer): (5*5+1)*6=156\n第2层(subsampling layer): 0\n第3层(convolutional layer): (5*5*6+1)*16=2416\n第4层(subsampling layer): 0\n第5层(fully connected layer): (5*5*16+1)*120=48120\n第6层(fully connected layer): (120+1)*84=10164\n第7层(fully connected layer): (84+1)*10=850\n\n参数总数：61,706\n")])])]),t("p",[_._v("由上面可以看出，"),t("strong",[_._v("卷积神经网络的参数大部分都在全连接层")]),_._v("。"),t("strong",[_._v("整个网络的计算速度取决于卷积层，整个网络的参数个数取决于全连接层。")])]),_._v(" "),t("h3",{attrs:{id:"_1-4-alexnet"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-alexnet"}},[_._v("#")]),_._v(" 1.4. AlexNet")]),_._v(" "),t("p",[_._v("2013 AlexNet")]),_._v(" "),t("p",[_._v("A. Krizhevsky, I. Sutskever and G. E. Hinton. ImageNet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing 25, MIT Press, Cambridge, MA, 2012.")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531152727_562fbbacef7e.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("ImageNet")]),_._v("包含超过120万张彩色图片，属于1000个不同类别，这是目前为止最大的图像识别数据库。"),t("strong",[_._v("Alex Krizhevsky")]),_._v("等人构建了一个包含65万多个神经元，待估计参数超过6000万的大规模网络，这一网络被称为AlexNet。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531161635_e586bf947ed0.png",alt:"img"}})]),_._v(" "),t("h3",{attrs:{id:"_1-5-alexnet-改进"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-alexnet-改进"}},[_._v("#")]),_._v(" 1.5. AlexNet 改进")]),_._v(" "),t("p",[_._v("（1）"),t("strong",[_._v("以ReLU函数代替 sigmoid 或 tanh 函数")]),_._v("，实践证明，这样做能"),t("strong",[_._v("使网络训练以更快速度收敛")]),_._v("。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531161204_c6fc26071864.png",alt:"img"}})]),_._v(" "),t("p",[_._v("使用relu激活函数，"),t("strong",[_._v("x<0时，y=0，使得不用每次都改变所有的值")]),_._v("，使收敛速度更快。同时"),t("strong",[_._v("x>0时，导数始终为1，避免了 sigmoid 和 tanh 在深层神经网络中梯度无法向前传很远的现象")]),_._v("。")]),_._v(" "),t("p",[_._v("（2）"),t("strong",[_._v("为降采样操作起了一个新的名字—池化（Pooling）")]),_._v(",意思是把邻近的像素作为一个“池子”来重新考虑。如图所示，左边所有红色的像素值可以看做是一个“池子”，经过池化操作后，变成右边的一个蓝色像素。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531161316_fd67653e0015.png",alt:"img"}})]),_._v(" "),t("p",[_._v("在AlexNet中，提出了 "),t("strong",[_._v("最大池化(Max Pooling)")]),_._v(" 的概念，即对"),t("strong",[_._v("每一个邻近像素组成的“池子”，选取像素最大值作为输出")]),_._v("。")]),_._v(" "),t("p",[_._v("在"),t("strong",[_._v("LeNet中，池化的像素是不重叠的；而在AlexNet中进行的是有重叠的池化")]),_._v("。实践表明，"),t("strong",[_._v("有重叠的最大池化能够很好的克服过拟合问题")]),_._v("，提升系统性能。")]),_._v(" "),t("p",[t("strong",[_._v("平均池化时，后向传播的梯度平均分配给原来的格子")]),_._v("。")]),_._v(" "),t("p",[_._v("那么"),t("strong",[_._v("最大池化")]),_._v("时，"),t("strong",[_._v("后向传播的梯度")]),_._v("怎么处理？"),t("strong",[_._v("赢者通吃，Winner takes all，最大的那个格子直接变成该梯度，其他都变成0。")])]),_._v(" "),t("p",[_._v("为什么最大池化比平均池化有效？")]),_._v(" "),t("ul",[t("li",[_._v("一，它做了降采样；")]),_._v(" "),t("li",[_._v("二，"),t("strong",[_._v("做了非线性变换，求最大值一定是非线性的")]),_._v("；")]),_._v(" "),t("li",[_._v("三，"),t("strong",[_._v("让pooling的那一层激活的神经元变少。max pooling只激活了最大的，其他的被屏蔽掉了")]),_._v("。"),t("strong",[_._v("当参数很多的时候，时刻要考虑收敛的问题。每一次不要让所有的神经元都被激活，否则每次更新时variation都会很大")]),_._v("。")])]),_._v(" "),t("p",[_._v("（3）随机丢弃（Dropout）")]),_._v(" "),t("p",[_._v("为了避免系统参数更新过快导致过拟合，每次利用训练样本更新参数时候，"),t("strong",[_._v("随机的“丢弃”一定比例的神经元")]),_._v("，被丢弃的神经元将不参加训练过程，输入和输出该神经元的权重系数也不做更新。")]),_._v(" "),t("p",[_._v("这样每次训练时，训练的网络架构都不一样，而这些不同的网络架构却分享共同的权重系数。实验表明，"),t("strong",[_._v("随机丢弃技术减缓了网络收敛速度，也以大概率避免了过拟合的发生。")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531161417_31358014565a.png",alt:"img"}})]),_._v(" "),t("p",[_._v("Dropout做法是，"),t("strong",[_._v("对每一层，每次训练时以概率p丢弃一些神经元，这样每次训练的网络都不一样")]),_._v("。")]),_._v(" "),t("p",[t("strong",[_._v("训练结束后的测试流程，要用完整的网络结构")]),_._v("，同时对该层的所有的参数（W,b）都要乘以(1-p)。")]),_._v(" "),t("p",[t("strong",[_._v("dropout和max pooling、relu函数的意义本质上是一样的")]),_._v("，"),t("strong",[_._v("每一次每层都让有限的神经元被激活，让不能收敛的网络快速收敛")]),_._v("。另外，dropout让网络处于不确定的量子态，相当于同时在训练一大堆网络，最后测试时再把这一大堆网络综合起来。")]),_._v(" "),t("p",[_._v("（4）"),t("strong",[_._v("增加训练样本")])]),_._v(" "),t("p",[_._v("尽管ImageNet的训练样本数量有超过120万幅图片，但相对于6亿待估计参数来说，训练图像仍然不够。")]),_._v(" "),t("p",[_._v("Alex等人采用了多种方法增加训练样本，包括：1. "),t("strong",[_._v("将原图水平翻转")]),_._v("；2. "),t("strong",[_._v("将256×256的图像随机选取224×224的片段作为输入图像")]),_._v("。运用上面两种方法的组合可以将一幅图像变为2048幅图像。3. 还可以对每幅图片"),t("strong",[_._v("引入一定的噪声")]),_._v("，构成新的图像。")]),_._v(" "),t("p",[_._v("这样做可以较大规模增加训练样本，避免由于训练样本不够造成的性能损失")]),_._v(" "),t("p",[_._v("（5）用GPU加速训练过程")]),_._v(" "),t("p",[_._v("采用2片GTX 580 GPU对训练过程进行加速，由于GPU强大的并行计算能力，使得训练过程的时间缩短数十倍，哪怕这样，训练时间仍然用了六天。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531161539_ce73adbcfa81.png",alt:"img"}})]),_._v(" "),t("p",[_._v("Alex Krizhevsky等人在ImageNet的测试集上获得了"),t("strong",[_._v("37.5%的Top 1错误率")]),_._v("（即正确的类不是测试中排名第一的类的百分率）和"),t("strong",[_._v("16.4%的Top 5错误率")]),_._v("（即正确的类不是测试中排名前五的类的百分率），遥遥领先。")]),_._v(" "),t("ul",[t("li",[t("strong",[_._v("TOP5错误率就是模型给出最大的5种可能，真正的结果不在这5种之中的错误率")]),_._v("。")]),_._v(" "),t("li",[t("strong",[_._v("TOP1错误率就是只给出一个答案")]),_._v("。")])]),_._v(" "),t("h3",{attrs:{id:"_1-6-caffe的优劣"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-caffe的优劣"}},[_._v("#")]),_._v(" 1.6. Caffe的优劣")]),_._v(" "),t("p",[_._v("优点")]),_._v(" "),t("ul",[t("li",[_._v("非常适合卷积神经网络做图像识别")]),_._v(" "),t("li",[_._v("预训练的model比较多")]),_._v(" "),t("li",[_._v("代码量少")]),_._v(" "),t("li",[t("strong",[_._v("封装比较少，源程序容易看懂，容易修改")])]),_._v(" "),t("li",[t("strong",[_._v("训练好的参数容易导出到其他程序文件 （如C语言）")])]),_._v(" "),t("li",[_._v("适合工业应用")])]),_._v(" "),t("p",[_._v("缺点")]),_._v(" "),t("ul",[t("li",[_._v("由于是专门为卷积神经网络开发的，结构不灵活，难以进行其他应用。")]),_._v(" "),t("li",[_._v("代码写法比较僵化，每一层都要写。")]),_._v(" "),t("li",[_._v("除非修改源码，否则不能完全调节所有细节。")])]),_._v(" "),t("p",[_._v("CAFFE2，2017年4月发布，在代码灵活性上做了一些工作。")]),_._v(" "),t("p",[_._v("深度学习已变成"),t("strong",[_._v("数据和运算能力的比拼，训练样本个数、GPU")]),_._v("。")]),_._v(" "),t("h3",{attrs:{id:"_1-7-近年来流行的网络结构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-7-近年来流行的网络结构"}},[_._v("#")]),_._v(" 1.7. 近年来流行的网络结构")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531165503_e8b008d02aea.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("各种不同网络在IMAGENET上的结果")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531171127_d6242f105662.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("不同网络识别率比较")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531171143_4dca73cca3fe.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("不同网络计算量和识别率的联合比较")])]),_._v(" "),t("h4",{attrs:{id:"_1-7-1-vggnet-simonyan-and-zisserman-2014"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-7-1-vggnet-simonyan-and-zisserman-2014"}},[_._v("#")]),_._v(" 1.7.1. VGGNet: （Simonyan and Zisserman, 2014）")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531171544_73b01d00e325.png",alt:"img"}})]),_._v(" "),t("p",[_._v("问题："),t("strong",[_._v("为何要将2个3*3卷积核叠到一起？")])]),_._v(" "),t("p",[t("strong",[_._v("因为2个叠到一起的"),t("code",[_._v("3*3")]),_._v("卷积核，感受野（Receptive Field）是"),t("code",[_._v("7*7")]),_._v(",大致可以替代7*7卷积核的作用。但这样做可以使参数更少 ，参数比例大致为18:49")])]),_._v(" "),t("ul",[t("li",[t("strong",[_._v("感受野：就是把卷积后的点倒推到原始的那幅图上去，两个"),t("code",[_._v("3*3")]),_._v("卷积核并排的感受野和一个"),t("code",[_._v("7*7")]),_._v("的感受野相同")]),_._v("。")]),_._v(" "),t("li",[_._v("VGGNet提高了一些识别率，但计算速度比AlexNet慢很多。因为卷积网络的计算速度主要和卷积核个数有关，VGG的卷积核很多，因此速度慢很多。")])]),_._v(" "),t("h4",{attrs:{id:"_1-7-2-googlenet-szegedy-2014"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-7-2-googlenet-szegedy-2014"}},[_._v("#")]),_._v(" 1.7.2. GoogLeNet: （Szegedy, 2014）")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531171705_a702f1d3830e.png",alt:"img"}})]),_._v(" "),t("ul",[t("li",[_._v("22层")]),_._v(" "),t("li",[t("strong",[_._v("inception 结构")]),_._v("，"),t("strong",[_._v("用一些"),t("code",[_._v("1*1")]),_._v(", "),t("code",[_._v("3*3")]),_._v("和"),t("code",[_._v("5*5")]),_._v("的小卷积核用固定方式组合到一起，来代替大的卷积核。达到增加感受野和减少参数的目的")]),_._v("。")]),_._v(" "),t("li",[_._v("500万参数，比ALEXNET小了12倍。")]),_._v(" "),t("li",[_._v("ILSVRC’14 测试冠军（6.7% TOP 5 ERROR）")])]),_._v(" "),t("p",[_._v("1*1的卷积核，其实只是在channel那个层面上做了加权平均。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531171853_4d68a6aa4766.png",alt:"img"}})]),_._v(" "),t("h4",{attrs:{id:"_1-7-3-resnet-he-et-al-2015"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-7-3-resnet-he-et-al-2015"}},[_._v("#")]),_._v(" 1.7.3. ResNet: （He et al, 2015）")]),_._v(" "),t("p",[_._v("Residual net，残差网络")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531171949_147400bff2c2.png",alt:"img"}})]),_._v(" "),t("ul",[t("li",[_._v("152层")]),_._v(" "),t("li",[_._v("ILSVRC’15冠军，（3.57 TOP 5 ERROR）")]),_._v(" "),t("li",[_._v("加入了前向输入机制，将前面层获得的特征图作为监督项输入到后面层。用这样的方法使深层网络训练能够收敛。")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531172041_28004bbd02cf.png",alt:"img"}})]),_._v(" "),t("p",[_._v("将浅层的输出直接加入到后面层去，促使深层网络能够表现更好。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200531172135_d212846d082e.png",alt:"img"}})]),_._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[_._v("ResNet训练技巧：\n-- Batch Normalization\n-- Xavier initialization\n-- SGD + Momentum (0.9)\n-- Learning Rate:0.1\n-- Batch size 256\n-- Weight decay 1e-5\n-- No dropout\n")])])]),t("p",[_._v("一般认为，一个比较深的，每层神经元个数少的网络，比一个比较浅的，每层神经元个数多的网络效果好，即"),t("strong",[_._v("深层比浅层好")]),_._v("。另外，计算复杂度和识别率需要权衡。")]),_._v(" "),t("h3",{attrs:{id:"_1-8-卷积神经网络的应用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-8-卷积神经网络的应用"}},[_._v("#")]),_._v(" 1.8. 卷积神经网络的应用")]),_._v(" "),t("ul",[t("li",[_._v("人脸识别")]),_._v(" "),t("li",[_._v("人脸特征点检测")]),_._v(" "),t("li",[_._v("卷积神经网络压缩")])]),_._v(" "),t("p",[t("strong",[_._v("卷积神经网络压缩：有了一个神经网络，尽可能降低它的复杂度，或者降低它的存储容量，同时又不能让它的识别率下降太多")]),_._v("。")]),_._v(" "),t("h3",{attrs:{id:"_1-9-transfer-learning迁移学习"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-9-transfer-learning迁移学习"}},[_._v("#")]),_._v(" 1.9. Transfer Learning迁移学习")]),_._v(" "),t("p",[t("strong",[_._v("把一个Domain的经验迁移到另一个Domain上去")]),_._v("。")]),_._v(" "),t("p",[_._v("比如之前一个用外国人脸训练的人脸识别模型，要想让它识别亚洲人的脸，可以用10万张亚洲人的脸对模型进行微调，再用4万张身份证人脸再进行调优。")]),_._v(" "),t("ul",[t("li",[t("strong",[_._v("用训练好的模型做特征提取器")]),_._v("，比如"),t("strong",[_._v("用AlexNet模型的输出，再进行神经网络或者SVM分类")]),_._v("，这种应用目前非常多。")]),_._v(" "),t("li",[t("strong",[_._v("也可以把训练好的模型当做识别器")]),_._v("，比如对AlexNet模型参数再进行几种水果的分类。")])])])}),[],!1,null,null,null);t.default=a.exports}}]);