(window.webpackJsonp=window.webpackJsonp||[]).push([[259],{866:function(t,a,_){"use strict";_.r(a);var r=_(42),e=Object(r.a)({},(function(){var t=this,a=t.$createElement,_=t._self._c||a;return _("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[_("ul",[_("li",[_("a",{attrs:{href:"#1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%88%86%E5%89%B2"}},[t._v("1. 目标检测与分割")]),t._v(" "),_("ul",[_("li",[_("a",{attrs:{href:"#11-%E5%87%A0%E7%A7%8D%E4%BB%BB%E5%8A%A1%E6%AF%94%E8%BE%83"}},[t._v("1.1. 几种任务比较")])]),t._v(" "),_("li",[_("a",{attrs:{href:"#12-adaboost%E7%9A%84%E5%BA%94%E7%94%A8"}},[t._v("1.2. AdaBoost的应用")]),t._v(" "),_("ul",[_("li",[_("a",{attrs:{href:"#121-%E6%9C%80%E8%83%BD%E8%A1%A8%E5%BE%81%E4%BA%BA%E8%84%B8%E7%9A%84haar%E7%89%B9%E5%BE%81"}},[t._v("1.2.1. 最能表征人脸的Haar特征：")])])])]),t._v(" "),_("li",[_("a",{attrs:{href:"#13-adaboost%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E6%B5%81%E7%A8%8B"}},[t._v("1.3. AdaBoost人脸检测流程")])]),t._v(" "),_("li",[_("a",{attrs:{href:"#14-%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB%E4%B8%8E%E5%AE%9A%E4%BD%8D"}},[t._v("1.4. 目标识别与定位")])]),t._v(" "),_("li",[_("a",{attrs:{href:"#15-%E5%A4%9A%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"}},[t._v("1.5. 多目标检测")]),t._v(" "),_("ul",[_("li",[_("a",{attrs:{href:"#151-2014-r-cnn-a-na%C3%AFve-deep-detection-model"}},[t._v("1.5.1. 2014-R-CNN, a naïve deep detection model")]),t._v(" "),_("ul",[_("li",[_("a",{attrs:{href:"#1511-region-proposals-selective-search-ss"}},[t._v("1.5.1.1. Region Proposals (Selective Search, SS)")])]),t._v(" "),_("li",[_("a",{attrs:{href:"#1512-region-proposals"}},[t._v("1.5.1.2. Region Proposals")])])])]),t._v(" "),_("li",[_("a",{attrs:{href:"#152-2015-fast-r-cnn-roi-pooling"}},[t._v("1.5.2. 2015-fast R-CNN, ROI pooling")]),t._v(" "),_("ul",[_("li",[_("a",{attrs:{href:"#1521-roi-pooling"}},[t._v("1.5.2.1. ROI Pooling")])])])]),t._v(" "),_("li",[_("a",{attrs:{href:"#153-2015-faster-r-cnn-rpn"}},[t._v("1.5.3. 2015-faster R-CNN, RPN")])])])]),t._v(" "),_("li",[_("a",{attrs:{href:"#16-mtcnn"}},[t._v("1.6. MTCNN")]),t._v(" "),_("ul",[_("li",[_("a",{attrs:{href:"#161-p-net-proposal-network-"}},[t._v("1.6.1. P-Net (Proposal Network )")])]),t._v(" "),_("li",[_("a",{attrs:{href:"#162-r-net-refine-network-"}},[t._v("1.6.2. R-Net (Refine Network )")])]),t._v(" "),_("li",[_("a",{attrs:{href:"#163-o-net-output-network-"}},[t._v("1.6.3. O-Net (Output Network )")])])])]),t._v(" "),_("li",[_("a",{attrs:{href:"#17-%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9Cfully-convolutional-networks"}},[t._v("1.7. 全卷积网络（Fully Convolutional Networks）")]),t._v(" "),_("ul",[_("li",[_("a",{attrs:{href:"#171-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B--%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"}},[t._v("1.7.1. 目标检测 – 语义分割")])]),t._v(" "),_("li",[_("a",{attrs:{href:"#172-pooling-%E5%B1%82%E7%9A%84%E4%B8%8A%E9%87%87%E6%A0%B7upsampling"}},[t._v("1.7.2. Pooling 层的上采样（Upsampling）")])]),t._v(" "),_("li",[_("a",{attrs:{href:"#173-%E5%8F%8D%E5%8D%B7%E7%A7%AF%E6%B5%81%E7%A8%8B"}},[t._v("1.7.3. 反卷积流程")])])])])])])]),t._v(" "),_("h2",{attrs:{id:"_1-目标检测与分割"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-目标检测与分割"}},[t._v("#")]),t._v(" 1. 目标检测与分割")]),t._v(" "),_("h3",{attrs:{id:"_1-1-几种任务比较"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-几种任务比较"}},[t._v("#")]),t._v(" 1.1. 几种任务比较")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("目标定位与识别最简单，只有一个目标")]),t._v("。")]),t._v(" "),_("li",[_("strong",[t._v("目标检测与分割其次，因为它有多个目标，每一个都要识别")]),t._v("。")]),t._v(" "),_("li",[_("strong",[t._v("语义分割最难，不仅有多个目标，还要明确标出分界线")]),t._v("。")]),t._v(" "),_("li",[_("strong",[t._v("识别任务也就是分类问题，比目标定位与识别更简单")]),t._v("，因为目标定位与识别不仅返回label，还要返回位置。")])]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606195402_fbf815589f6c.png",alt:"img"}})]),t._v(" "),_("p",[t._v("对于第二个和第三个任务，"),_("strong",[t._v("可以以某一个很小的方框依次扫描整个图")]),t._v("，从每一个采集到的图像中，送到识别器中，看是否是想要的。"),_("strong",[t._v("然后把方框逐渐变大")]),t._v("，再从头到尾扫描。")]),t._v(" "),_("h3",{attrs:{id:"_1-2-adaboost的应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-adaboost的应用"}},[t._v("#")]),t._v(" 1.2. AdaBoost的应用")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606200307_e6de953fbb55.png",alt:"img"}})]),t._v(" "),_("p",[t._v("最巧妙的地方在"),_("strong",[t._v("特征提取器和积分图")]),t._v("，只用加加减减就完成了特征提取。")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606200346_9b642eff3301.png",alt:"img"}})]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606200427_bcd905509685.png",alt:"img"}})]),t._v(" "),_("p",[_("strong",[t._v("比如第一个feature，3次加减法算白的，3次加减法算黑的，再用1次加减法算白减黑，共7次")]),t._v("。")]),t._v(" "),_("p",[t._v("分类器构造：取一些人脸（6000张左右）和一些非人脸（7万张）作为训练样本。总共特征，也就是f有20万。")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606200901_1ceadff6a018.png",alt:"img"}})]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606200934_9ced3d1d8e12.png",alt:"img"}})]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606200917_e08a72e3167b.png",alt:"img"}})]),t._v(" "),_("p",[_("strong",[t._v("对每一个特征构造一个分类器，也就是20万个弱分类器，然后用AdaBoost组合这些弱分类器")]),t._v("。")]),t._v(" "),_("p",[t._v("具体流程：")]),t._v(" "),_("ol",[_("li",[t._v("首先在数据集D中选取正确率最高的特征， 用F1表示。")]),t._v(" "),_("li",[t._v("将数据集D分为两类，{F1分对的数据}和{F1分错的数据}。")]),t._v(" "),_("li",[t._v("以较大概率取F1分错的数据，以较小概率去F1分对的数据，形成新的集合D2。")]),t._v(" "),_("li",[t._v("在D2中选取正确率最高的特征，用F2表示。")]),t._v(" "),_("li",[t._v("将D分为： {F1、F2都分对的数据}，{F1分对而F2分错的数据，以及F1分错而F2分对的数据}，{F1，F2都分错的数据}。")]),t._v(" "),_("li",[t._v("以最大概率取{F1，F2都分错的数据},以次大概率取{F1分对而F2分错的数据，以及F1分错而F2分对的数据}， 以最小概率取{F1、F2都分对的数据}，得到数据集D3.")]),t._v(" "),_("li",[t._v("在D3中选取正确率最高的特征，用F3表示。循环，以此类推。")]),t._v(" "),_("li",[t._v("用各个特征的线性组合构建分类器。")])]),t._v(" "),_("h4",{attrs:{id:"_1-2-1-最能表征人脸的haar特征"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-1-最能表征人脸的haar特征"}},[t._v("#")]),t._v(" 1.2.1. 最能表征人脸的Haar特征：")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606201749_278483bdd04d.png",alt:"img"}})]),t._v(" "),_("p",[t._v("第1个特征是，"),_("strong",[t._v("眼睛下面这一块减去眼睛的像素")]),t._v("，说明这一块最能区别人脸和非人脸。第二个也差不多，第三个是面部中央减两边。")]),t._v(" "),_("h3",{attrs:{id:"_1-3-adaboost人脸检测流程"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-adaboost人脸检测流程"}},[t._v("#")]),t._v(" 1.3. AdaBoost人脸检测流程")]),t._v(" "),_("ol",[_("li",[t._v("在图像中，"),_("strong",[t._v("对每一个24*24的格子遍历使用分类器")]),t._v("，如果是人脸，则输出。")]),t._v(" "),_("li",[_("strong",[t._v("将图像缩小，长宽同时除以1.2")]),t._v("，在用分类器遍历每一个24*24的格子。如果是人脸，将该处位置坐标乘以1.2， 等比例放大到原图。")]),t._v(" "),_("li",[_("strong",[t._v("重复2，直到图像长或宽小于24个像素为止")]),t._v("。")])]),t._v(" "),_("h3",{attrs:{id:"_1-4-目标识别与定位"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-目标识别与定位"}},[t._v("#")]),t._v(" 1.4. 目标识别与定位")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606212017_eab7f167d7d3.png",alt:"img"}})]),t._v(" "),_("ul",[_("li",[t._v("multi-task，同时进行两个任务，分类和定位。")]),t._v(" "),_("li",[_("strong",[t._v("单目标检测和多目标检测的区别在于目标的不确定性")]),t._v("。")])]),t._v(" "),_("h3",{attrs:{id:"_1-5-多目标检测"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-多目标检测"}},[t._v("#")]),t._v(" 1.5. 多目标检测")]),t._v(" "),_("p",[t._v("如何将卷积神经网络（CNN）用在目标检测上 ?")]),t._v(" "),_("p",[t._v("主要问题:")]),t._v(" "),_("ul",[_("li",[t._v("用大大小小的方框遍历所有图像不现实，"),_("strong",[t._v("如何快速挑出可能有物体的区域（Region of Interest, ROI）")]),t._v("。")]),t._v(" "),_("li",[t._v("我们需要一个计算量不那么大的算法，"),_("strong",[t._v("提出ROI的候选区域（Region of Proposals, or Proposals）")])])]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606212143_4fed3081b6a0.png",alt:"img"}})]),t._v(" "),_("p",[t._v("主要有三篇层层递进的文章。")]),t._v(" "),_("h4",{attrs:{id:"_1-5-1-2014-r-cnn-a-naive-deep-detection-model"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-1-2014-r-cnn-a-naive-deep-detection-model"}},[t._v("#")]),t._v(" 1.5.1. 2014-R-CNN, a naïve deep detection model")]),t._v(" "),_("p",[t._v('Girshick, Ross, et al. "Rich feature hierarchies for accurate object detection and semantic segmentation." CVPR. 2014.')]),t._v(" "),_("p",[t._v("Basic Ideas:")]),t._v(" "),_("ol",[_("li",[t._v("Use "),_("strong",[t._v("selective search")]),t._v(" to generate proposals")]),t._v(" "),_("li",[_("strong",[t._v("Scale and resize proposals")]),t._v(" to fit the CNN")]),t._v(" "),_("li",[_("strong",[t._v("SVM")]),t._v(" for final decisions")])]),t._v(" "),_("p",[t._v("Main Problems:")]),t._v(" "),_("ol",[_("li",[t._v("High cost to **perform Selective Search **(~5s per image)")]),t._v(" "),_("li",[t._v("Too many passes to CNN (~2000 proposals per image)")]),t._v(" "),_("li",[t._v("Lead to "),_("strong",[t._v("unacceptable test time")]),t._v(" (~50s per image)")]),t._v(" "),_("li",[t._v("High space cost to train SVM (millions of 1024-d features)")])]),t._v(" "),_("p",[t._v("流程图：")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606212320_4502c3eb2c0a.png",alt:"img"}})]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606212401_c60f7e2d6db2.png",alt:"img"}})]),t._v(" "),_("h5",{attrs:{id:"_1-5-1-1-region-proposals-selective-search-ss"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-1-1-region-proposals-selective-search-ss"}},[t._v("#")]),t._v(" 1.5.1.1. Region Proposals (Selective Search, SS)")]),t._v(" "),_("p",[t._v("给定一张图片，首先使用 Efficient Graph-BasedImage Segmentation 算法，"),_("strong",[t._v("将图片进行过分割 (Over-Segmentation)")])]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606212549_e441c1b83cff.png",alt:"img"}})]),t._v(" "),_("p",[t._v("如图所示，"),_("strong",[t._v("过分割后的每个region非常小，以此为基础，对相邻的region进行相似度判断并融合，形成不同尺度下的region。每个region对应一个bounding")]),t._v("。")]),t._v(" "),_("p",[t._v("selective search，位置比较相近、纹理灰度等特征相似的划分为一个区域。2014年的这篇文章中，一幅图像给出2000个左右的region proposal。")]),t._v(" "),_("h5",{attrs:{id:"_1-5-1-2-region-proposals"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-1-2-region-proposals"}},[t._v("#")]),t._v(" 1.5.1.2. Region Proposals")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606212716_1fd3ffb9fbf0.png",alt:"img"}})]),t._v(" "),_("p",[t._v("问题：")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("非常缓慢")])]),t._v(" "),_("li",[_("strong",[t._v("做了很多重复工作")]),t._v("，比如一个大的框放进CNN做了卷积，包含了里面的小的方框，它也被放进CNN，也做了卷积。")])]),t._v(" "),_("h4",{attrs:{id:"_1-5-2-2015-fast-r-cnn-roi-pooling"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-2-2015-fast-r-cnn-roi-pooling"}},[t._v("#")]),t._v(" 1.5.2. 2015-fast R-CNN, ROI pooling")]),t._v(" "),_("p",[t._v('Girshick, Ross. "Fast r-cnn." CVPR. 2015.')]),t._v(" "),_("p",[t._v("Basic Ideas:")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("Reduce the computation redundancy caused by overlaps")])])]),t._v(" "),_("p",[t._v("Main Contributions:")]),t._v(" "),_("ol",[_("li",[_("strong",[t._v("ROI pooling layer")])]),t._v(" "),_("li",[_("strong",[t._v("Replace SVM with softmax inside CNN")])]),t._v(" "),_("li",[t._v("Use SVD to accelerate fully connected layer")])]),t._v(" "),_("p",[t._v("Main Problems:")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("SS costs too much time")]),t._v(" (~2s for a fast version)")])]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606212913_904b07ece14b.png",alt:"img"}})]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606212935_6312cc51b6bb.png",alt:"img"}})]),t._v(" "),_("h5",{attrs:{id:"_1-5-2-1-roi-pooling"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-2-1-roi-pooling"}},[t._v("#")]),t._v(" 1.5.2.1. ROI Pooling")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606213001_ecbfb3c3e316.png",alt:"img"}})]),t._v(" "),_("p",[_("strong",[t._v("ROI pooling，对于不同大小的region proposal，在中间的某一层把它们归一化成统一的形状")]),t._v("。也就是对整个图像做卷积，在后面的层中将其大大小小分开。")]),t._v(" "),_("p",[t._v("现在生成selective search还是很慢，每张图片需要5s，")]),t._v(" "),_("h4",{attrs:{id:"_1-5-3-2015-faster-r-cnn-rpn"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-3-2015-faster-r-cnn-rpn"}},[t._v("#")]),t._v(" 1.5.3. 2015-faster R-CNN, RPN")]),t._v(" "),_("p",[t._v('Ren, Shaoqing, et al. "Faster R-CNN: Towards real-time object detection with region proposal networks." NIPS. 2015.')]),t._v(" "),_("p",[t._v("Basic Ideas:")]),t._v(" "),_("ul",[_("li",[_("strong",[t._v("Reduce the time of generating region proposals")])])]),t._v(" "),_("p",[t._v("Main Contributions:")]),t._v(" "),_("ol",[_("li",[_("strong",[t._v("Region Proposal Network (RPN)")])]),t._v(" "),_("li",[_("strong",[t._v("An end to end model")]),t._v(" finally!")])]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606213202_58f009fe44a9.png",alt:"img"}})]),t._v(" "),_("p",[t._v("对于特征图某个固定点，ANCHOR 生成9个矩形，共有3种形状，"),_("strong",[t._v("长宽比为大约为：width:height = [1:1, 1:2, 2:1]三种，实际上通过anchors就引入了检测中常用到的多尺度方法")]),t._v("。")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606213655_73a41b44d83b.png",alt:"img"}})]),t._v(" "),_("p",[t._v("把任意大小的输入图像reshape成800x600（即图2中的M=800，N=600）。再回头来看anchors的大小，anchors中长宽1:2中最大为352x704，长宽2:1中最大736x384，基本是cover了800x600的各个尺度和形状。")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606213710_7518e549aa27.png",alt:"img"}})]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606213737_7f9dca133c2d.png",alt:"img"}})]),t._v(" "),_("p",[t._v("Faster R-CNN检测结果")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606213819_122fb9368fb7.png",alt:"img"}})]),t._v(" "),_("p",[t._v("运行时间对比")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606213859_dfd36332fc9b.png",alt:"img"}})]),t._v(" "),_("p",[t._v("在PASCAL VOC上的性能对比")]),t._v(" "),_("h3",{attrs:{id:"_1-6-mtcnn"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-mtcnn"}},[t._v("#")]),t._v(" 1.6. MTCNN")]),t._v(" "),_("p",[t._v("目标检测 – 以人脸检测为例")]),t._v(" "),_("p",[t._v("Zhang K, Zhang Z, Li Z, et al. Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks.")]),t._v(" "),_("p",[t._v("Multitask:")]),t._v(" "),_("ol",[_("li",[t._v("Face detection")]),t._v(" "),_("li",[t._v("Facial landmarks localization")])]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606220530_c212f7b94fac.png",alt:"img"}})]),t._v(" "),_("h4",{attrs:{id:"_1-6-1-p-net-proposal-network"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-1-p-net-proposal-network"}},[t._v("#")]),t._v(" 1.6.1. P-Net (Proposal Network )")]),t._v(" "),_("p",[_("strong",[t._v("该网络主要是检测图中人脸，产生多个人脸候选框和回归向量")]),t._v("，再用回归向量对候选窗口进行校准，最后通过非极大值抑制NMS来合并高度重叠的候选框。")]),t._v(" "),_("h4",{attrs:{id:"_1-6-2-r-net-refine-network"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-2-r-net-refine-network"}},[t._v("#")]),t._v(" 1.6.2. R-Net (Refine Network )")]),t._v(" "),_("p",[_("strong",[t._v("该网络同样输出候选框置信度（根据置信度削减候选框数量）和回归向量")]),t._v("，通过边界框回归和NMS精调候选框的位置。")]),t._v(" "),_("h4",{attrs:{id:"_1-6-3-o-net-output-network"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-3-o-net-output-network"}},[t._v("#")]),t._v(" 1.6.3. O-Net (Output Network )")]),t._v(" "),_("p",[t._v("比R-Net层又多了一层卷积层，处理结果更加精细，作用和R-Net层作用一样（削减框数量同时精调回归框）。再者，该层对人脸区域进行了更多的监督，"),_("strong",[t._v("最后输出5个人脸关键点坐标")]),t._v("。")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606220755_bba802aef1c3.png",alt:"img"}})]),t._v(" "),_("h3",{attrs:{id:"_1-7-全卷积网络-fully-convolutional-networks"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-7-全卷积网络-fully-convolutional-networks"}},[t._v("#")]),t._v(" 1.7. 全卷积网络（Fully Convolutional Networks）")]),t._v(" "),_("h4",{attrs:{id:"_1-7-1-目标检测-语义分割"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-7-1-目标检测-语义分割"}},[t._v("#")]),t._v(" 1.7.1. 目标检测 – 语义分割")]),t._v(" "),_("p",[t._v("Long, Shelhamer and Darreli, Fully Convolutional Networks for Semantic Segmentation, CVPR 2015")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606220921_631ff0562ef8.png",alt:"img"}})]),t._v(" "),_("p",[_("strong",[t._v("全卷积网络完全对称，并且先训练降采样部分，然后固定前面，再训练升采样部分")]),t._v("。")]),t._v(" "),_("h4",{attrs:{id:"_1-7-2-pooling-层的上采样-upsampling"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-7-2-pooling-层的上采样-upsampling"}},[t._v("#")]),t._v(" 1.7.2. Pooling 层的上采样（Upsampling）")]),t._v(" "),_("p",[t._v("（a） Average pooling")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606221000_2413d649a015.png",alt:"img"}})]),t._v(" "),_("p",[t._v("（b） Max pooling")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606221038_a9a4c1b270e1.png",alt:"img"}})]),t._v(" "),_("p",[_("strong",[t._v("降采样中，最大池化时，需要记住最大值的位置。然后升采样中，把非最大值位置全赋0。")])]),t._v(" "),_("p",[t._v("卷积层的上采样（Upsampling），也叫反卷积（Deconvolution）或 转置卷积（Transpose Convolution）")]),t._v(" "),_("p",[t._v("考虑如下一个卷积层，输入特征图4"),_("em",[t._v("4，卷积核3")]),t._v("3，步长1，卷积后获得特征图维度为2*2，卷积流程：")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606221204_0a631e58ca4b.png",alt:"img"}})]),t._v(" "),_("h4",{attrs:{id:"_1-7-3-反卷积流程"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-7-3-反卷积流程"}},[t._v("#")]),t._v(" 1.7.3. 反卷积流程")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606221225_b3979d058905.png",alt:"img"}})]),t._v(" "),_("p",[t._v("全卷积网络还可以用在"),_("strong",[t._v("边缘提取、视频场景人数估计上")]),t._v("。")]),t._v(" "),_("p",[_("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200606221339_7b6dabc508b1.png",alt:"img"}})])])}),[],!1,null,null,null);a.default=e.exports}}]);