(window.webpackJsonp=window.webpackJsonp||[]).push([[245],{807:function(_,t,v){"use strict";v.r(t);var a=v(25),s=Object(a.a)({},(function(){var _=this,t=_._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[t("ul",[t("li",[t("a",{attrs:{href:"#1-%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"}},[_._v("1. 一文看懂集成学习")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#11-%E4%BB%80%E4%B9%88%E6%98%AF%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"}},[_._v("1.1. 什么是集成学习？")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#12-bagging"}},[_._v("1.2. Bagging")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#121-%E5%85%B7%E4%BD%93%E8%BF%87%E7%A8%8B"}},[_._v("1.2.1. 具体过程")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#%E4%B8%BE%E4%BE%8B"}},[_._v("举例")])])])]),_._v(" "),t("li",[t("a",{attrs:{href:"#13-boosting"}},[_._v("1.3. Boosting")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#131-%E5%85%B7%E4%BD%93%E8%BF%87%E7%A8%8B"}},[_._v("1.3.1. 具体过程")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#%E4%B8%BE%E4%BE%8B-1"}},[_._v("举例")])])])]),_._v(" "),t("li",[t("a",{attrs:{href:"#14-bagging-%E5%92%8C-boosting-%E7%9A%844-%E7%82%B9%E5%B7%AE%E5%88%AB"}},[_._v("1.4. Bagging 和 Boosting 的4 点差别")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#141-%E6%A0%B7%E6%9C%AC%E9%80%89%E6%8B%A9%E4%B8%8A"}},[_._v("1.4.1. 样本选择上")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#142-%E6%A0%B7%E4%BE%8B%E6%9D%83%E9%87%8D"}},[_._v("1.4.2. 样例权重")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#143-%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0"}},[_._v("1.4.3. 预测函数")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#144-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97"}},[_._v("1.4.4. 并行计算")])])])])])])]),_._v(" "),t("h2",{attrs:{id:"_1-一文看懂集成学习"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-一文看懂集成学习"}},[_._v("#")]),_._v(" 1. 一文看懂集成学习")]),_._v(" "),t("h3",{attrs:{id:"_1-1-什么是集成学习"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-什么是集成学习"}},[_._v("#")]),_._v(" 1.1. 什么是集成学习？")]),_._v(" "),t("p",[t("strong",[_._v("集成学习归属于机器学习，他是一种「训练思路」，并不是某种具体的方法或者算法")]),_._v("。")]),_._v(" "),t("p",[_._v("现实生活中，大家都知道 "),t("strong",[_._v("「人多力量大」，「3 个臭皮匠顶个诸葛亮」")]),_._v("。而集成学习的核心思路就是「人多力量大」，它并没有创造出新的算法，而是把已有的算法进行结合，从而得到更好的效果。")]),_._v(" "),t("p",[t("strong",[_._v("集成学习会挑选一些简单的基础模型进行组装")]),_._v("，组装这些基础模型的思路主要有 2 种方法：")]),_._v(" "),t("ul",[t("li",[t("strong",[_._v("bagging（bootstrap aggregating的缩写，也称作“套袋法”）")])]),_._v(" "),t("li",[t("strong",[_._v("boosting")])])]),_._v(" "),t("h3",{attrs:{id:"_1-2-bagging"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-bagging"}},[_._v("#")]),_._v(" 1.2. Bagging")]),_._v(" "),t("p",[t("strong",[_._v("Bagging 的核心思路是 — — 民主")]),_._v("。")]),_._v(" "),t("p",[_._v("Bagging 的思路是所有基础模型都一致对待，"),t("strong",[_._v("每个基础模型手里都只有一票。然后使用民主投票的方式得到最终的结果")]),_._v("。")]),_._v(" "),t("p",[_._v("大部分情况下，"),t("strong",[_._v("经过 bagging 得到的结果方差（variance）更小。")])]),_._v(" "),t("h4",{attrs:{id:"_1-2-1-具体过程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-1-具体过程"}},[_._v("#")]),_._v(" 1.2.1. 具体过程")]),_._v(" "),t("ol",[t("li",[_._v("从原始样本集中抽取训练集。"),t("strong",[_._v("每轮从原始样本集中使用Bootstraping的方法抽取n个训练样本（在训练集中，有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中")]),_._v("）。"),t("strong",[_._v("共进行k轮抽取，得到k个训练集")]),_._v("。（k个训练集之间是相互独立的）")]),_._v(" "),t("li",[t("strong",[_._v("每次使用一个训练集得到一个模型，k个训练集共得到k个模型。")]),_._v("（注：这里并没有具体的分类算法或回归方法，我们可以根据具体问题采用不同的分类或回归方法，如决策树、感知器等）")]),_._v(" "),t("li",[t("strong",[_._v("对分类问题：将上步得到的k个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果")]),_._v("。（所有模型的重要性相同）")])]),_._v(" "),t("h4",{attrs:{id:"举例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#举例"}},[_._v("#")]),_._v(" 举例")]),_._v(" "),t("ul",[t("li",[_._v("在 bagging 的方法中，"),t("strong",[_._v("最广为熟知的就是随机森林了：bagging + 决策树 = 随机森林")])])]),_._v(" "),t("h3",{attrs:{id:"_1-3-boosting"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-boosting"}},[_._v("#")]),_._v(" 1.3. Boosting")]),_._v(" "),t("p",[t("strong",[_._v("Boosting 的核心思路是 — — 挑选精英")]),_._v("。")]),_._v(" "),t("p",[_._v("Boosting 和 bagging 最本质的差别在于他对基础模型不是一致对待的，而是"),t("strong",[_._v("经过不停的考验和筛选来挑选出「精英」，然后给精英更多的投票权，表现不好的基础模型则给较少的投票权，然后综合所有人的投票得到最终结果")]),_._v("。")]),_._v(" "),t("p",[_._v("大部分情况下，"),t("strong",[_._v("经过 boosting 得到的结果偏差（bias）更小")]),_._v("。")]),_._v(" "),t("h4",{attrs:{id:"_1-3-1-具体过程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-1-具体过程"}},[_._v("#")]),_._v(" 1.3.1. 具体过程")]),_._v(" "),t("ol",[t("li",[_._v("通过加法模型将基础模型进行线性的组合。")]),_._v(" "),t("li",[t("strong",[_._v("每一轮训练都提升那些错误率小的基础模型权重，同时减小错误率高的模型权重")]),_._v("。")]),_._v(" "),t("li",[_._v("在每一轮改变训练数据的权值或概率分布，"),t("strong",[_._v("通过提高那些在前一轮被弱分类器分错样例的权值，减小前一轮分对样例的权值")]),_._v("，来使得分类器对误分的数据有较好的效果。")])]),_._v(" "),t("h4",{attrs:{id:"举例-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#举例-2"}},[_._v("#")]),_._v(" 举例")]),_._v(" "),t("ul",[t("li",[t("strong",[_._v("在 boosting 的方法中，比较主流的有 Adaboost 和 Gradient boosting")]),_._v(" 。")])]),_._v(" "),t("h3",{attrs:{id:"_1-4-bagging-和-boosting-的4-点差别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-bagging-和-boosting-的4-点差别"}},[_._v("#")]),_._v(" 1.4. Bagging 和 Boosting 的4 点差别")]),_._v(" "),t("h4",{attrs:{id:"_1-4-1-样本选择上"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-1-样本选择上"}},[_._v("#")]),_._v(" 1.4.1. 样本选择上")]),_._v(" "),t("ul",[t("li",[t("strong",[_._v("Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的")]),_._v("。")]),_._v(" "),t("li",[t("strong",[_._v("Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化")]),_._v("。而权值是根据上一轮的分类结果进行调整。")])]),_._v(" "),t("h4",{attrs:{id:"_1-4-2-样例权重"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-2-样例权重"}},[_._v("#")]),_._v(" 1.4.2. 样例权重")]),_._v(" "),t("ul",[t("li",[_._v("Bagging：使用均匀取样，"),t("strong",[_._v("每个样例的权重相等")])]),_._v(" "),t("li",[_._v("Boosting：根据错误率不断调整样例的权值，"),t("strong",[_._v("错误率越大则权重越大")]),_._v("。")])]),_._v(" "),t("h4",{attrs:{id:"_1-4-3-预测函数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-3-预测函数"}},[_._v("#")]),_._v(" 1.4.3. 预测函数")]),_._v(" "),t("ul",[t("li",[_._v("Bagging："),t("strong",[_._v("所有预测函数的权重相等")]),_._v("。")]),_._v(" "),t("li",[_._v("Boosting：每个弱分类器都有相应的权重，"),t("strong",[_._v("对于分类误差小的分类器会有更大的权重")]),_._v("。")])]),_._v(" "),t("h4",{attrs:{id:"_1-4-4-并行计算"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-4-并行计算"}},[_._v("#")]),_._v(" 1.4.4. 并行计算")]),_._v(" "),t("ul",[t("li",[_._v("Bagging："),t("strong",[_._v("各个预测函数可以并行生成")])]),_._v(" "),t("li",[_._v("Boosting："),t("strong",[_._v("各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果")]),_._v("。")])])])}),[],!1,null,null,null);t.default=s.exports}}]);