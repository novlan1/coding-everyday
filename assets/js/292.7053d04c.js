(window.webpackJsonp=window.webpackJsonp||[]).push([[292],{594:function(_,v,t){"use strict";t.r(v);var a=t(25),r=Object(a.a)({},(function(){var _=this,v=_._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[v("ul",[v("li",[v("a",{attrs:{href:"#1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8"}},[_._v("1. 深度学习入门")]),_._v(" "),v("ul",[v("li",[v("a",{attrs:{href:"#11-%E5%88%86%E7%B1%BB%E5%8F%8A%E5%85%B6%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F"}},[_._v("1.1. 分类及其性能度量")]),_._v(" "),v("ul",[v("li",[v("a",{attrs:{href:"#111-%E5%88%86%E7%B1%BB%E5%87%86%E7%A1%AE%E7%8E%87"}},[_._v("1.1.1. 分类准确率")])]),_._v(" "),v("li",[v("a",{attrs:{href:"#112-%E7%B2%BE%E7%A1%AE%E7%8E%87precision%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87recall%E6%9B%B4%E5%85%B3%E6%B3%A8%E6%AD%A3%E7%B1%BB"}},[_._v("1.1.2. 精确率"),v("code",[_._v("precision")]),_._v("和召回率"),v("code",[_._v("recall")]),_._v("，更关注正类")])])])]),_._v(" "),v("li",[v("a",{attrs:{href:"#12-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"}},[_._v("1.2. 特征工程")])]),_._v(" "),v("li",[v("a",{attrs:{href:"#13-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E5%8C%BA%E5%88%AB"}},[_._v("1.3. 机器学习和数据挖掘的区别？")])]),_._v(" "),v("li",[v("a",{attrs:{href:"#14-%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%88%92%E5%88%86%E6%96%B9%E6%B3%95"}},[_._v("1.4. 训练集和测试集的划分方法")])]),_._v(" "),v("li",[v("a",{attrs:{href:"#15-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB"}},[_._v("1.5. 机器学习分类")]),_._v(" "),v("ul",[v("li",[v("a",{attrs:{href:"#151-%E5%9B%9E%E5%BD%92%E5%92%8C%E5%88%86%E7%B1%BB%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB"}},[_._v("1.5.1. 回归和分类的区别和联系")])])])]),_._v(" "),v("li",[v("a",{attrs:{href:"#16-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7"}},[_._v("1.6. 特征提取的重要性")])])])])]),_._v(" "),v("h2",{attrs:{id:"_1-深度学习入门"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-深度学习入门"}},[_._v("#")]),_._v(" 1. 深度学习入门")]),_._v(" "),v("h3",{attrs:{id:"_1-1-分类及其性能度量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-分类及其性能度量"}},[_._v("#")]),_._v(" 1.1. 分类及其性能度量")]),_._v(" "),v("p",[_._v("通常将关注的类称为正类。")]),_._v(" "),v("table",[v("thead",[v("tr",[v("th"),_._v(" "),v("th"),_._v(" "),v("th",[_._v("预测")]),_._v(" "),v("th")])]),_._v(" "),v("tbody",[v("tr",[v("td"),_._v(" "),v("td"),_._v(" "),v("td",[_._v("正样本")]),_._v(" "),v("td",[_._v("负样本")])]),_._v(" "),v("tr",[v("td",[_._v("实际")]),_._v(" "),v("td",[_._v("正样本")]),_._v(" "),v("td",[_._v("True Positive (TP)")]),_._v(" "),v("td",[_._v("False Negative (FN)")])]),_._v(" "),v("tr",[v("td"),_._v(" "),v("td",[_._v("负样本")]),_._v(" "),v("td",[_._v("False Positive (FP)")]),_._v(" "),v("td",[_._v("True Negative (TN)")])])])]),_._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[_._v("预测类别          正例   负例   总计\n实际类别　　正例    TP    FN     P(实际为正)\n　　　　　　负例    FP    TN     N(实际为负)\n")])])]),v("p",[v("img",{attrs:{src:"/imgs/hunxiaojuzhen.png",alt:"混淆矩阵"}})]),_._v(" "),v("h4",{attrs:{id:"_1-1-1-分类准确率"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-1-分类准确率"}},[_._v("#")]),_._v(" 1.1.1. 分类准确率")]),_._v(" "),v("p",[v("code",[_._v("accuraty：(TP + TN)/(P+N)")])]),_._v(" "),v("p",[_._v("弊端：100条短信中，只有1条是垃圾短信，将其都归为非垃圾短信，准确率为99%，显然不合适。")]),_._v(" "),v("h4",{attrs:{id:"_1-1-2-精确率precision和召回率recall-更关注正类"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-2-精确率precision和召回率recall-更关注正类"}},[_._v("#")]),_._v(" 1.1.2. 精确率"),v("code",[_._v("precision")]),_._v("和召回率"),v("code",[_._v("recall")]),_._v("，更关注正类")]),_._v(" "),v("p",[v("code",[_._v("precision = TP/(TP + FP)")]),_._v("，指模型判定的正例中真正正例的比例。比如预测出的垃圾短信中真正垃圾短信的比例。")]),_._v(" "),v("p",[v("code",[_._v("recall = TP/(TP+FN) = TP/P")]),_._v("，指总正例中被模型正确判定正例的比重。医学上称为灵敏度("),v("code",[_._v("sensitivity")]),_._v(")。比如所有真的垃圾短信被正确找出来的比例。")]),_._v(" "),v("p",[v("strong",[_._v("查准率：精确率；")]),_._v(" "),v("strong",[_._v("查全率：召回率。")])]),_._v(" "),v("p",[_._v("精确率和召回率的关系："),v("strong",[_._v("撒网打鱼，如果网很大，打上来的鱼很多，召回率很大，但也会打上很多石头，精确率就会比较低。")])]),_._v(" "),v("p",[_._v("PR曲线"),v("code",[_._v("(x-R, y-P)")]),_._v("下的面积，"),v("code",[_._v("Area Under Curve")]),_._v(", 简称AUC")]),_._v(" "),v("p",[_._v("Area有助于弥补P、R的单点值局限性，可以反映全局性能。")]),_._v(" "),v("h3",{attrs:{id:"_1-2-特征工程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-特征工程"}},[_._v("#")]),_._v(" 1.2. 特征工程")]),_._v(" "),v("p",[_._v("当你做特征工程时，其实是"),v("strong",[_._v("将数据属性转换为数据特征")]),_._v("的过程。")]),_._v(" "),v("p",[_._v("属性代表了数据的所有维度，在数据建模时，如果对原始数据的所有属性进行学习，并不能很好的找到数据的潜在趋势。\n而通过特征工程对你的数据进行预处理的话，你的算法模型能够减少受到噪声的干扰，这样能够更好的找出趋势；")]),_._v(" "),v("p",[v("strong",[_._v("数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已")]),_._v("。")]),_._v(" "),v("p",[_._v("比如词根提取和词形还原等。")]),_._v(" "),v("h3",{attrs:{id:"_1-3-机器学习和数据挖掘的区别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-机器学习和数据挖掘的区别"}},[_._v("#")]),_._v(" 1.3. 机器学习和数据挖掘的区别？")]),_._v(" "),v("p",[_._v("数据挖掘偏应用，机器学习偏理论；数据挖掘是利用机器学习的技术，加上数据库知识，挖掘海量信息。")]),_._v(" "),v("p",[_._v("分类器三步：训练阶段、测试阶段、工作阶段")]),_._v(" "),v("h3",{attrs:{id:"_1-4-训练集和测试集的划分方法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-训练集和测试集的划分方法"}},[_._v("#")]),_._v(" 1.4. 训练集和测试集的划分方法")]),_._v(" "),v("ul",[v("li",[_._v("留出法（留出一部分测试）")]),_._v(" "),v("li",[_._v("交叉验证法（分层取样）")]),_._v(" "),v("li",[_._v("自助法（有放回的取样本）")])]),_._v(" "),v("h3",{attrs:{id:"_1-5-机器学习分类"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-机器学习分类"}},[_._v("#")]),_._v(" 1.5. 机器学习分类")]),_._v(" "),v("p",[_._v("根据任务是"),v("strong",[_._v("预测标签还是预测最后的结果")]),_._v("，将机器学习分为强化学习("),v("code",[_._v("reinforcement learning")]),_._v(")和（有监督、无监督、半监督）。")]),_._v(" "),v("ul",[v("li",[_._v("比如说，下棋不关心每一步对或错，只关心最后赢或输，又比如自动驾驶，不关心每一步向左或向右，关心的是到达终点的用时。")])]),_._v(" "),v("p",[_._v("有监督、无监督的区别是训练时有无label，有监督又可分为分类和回归，其区别是label是离散还是连续。")]),_._v(" "),v("ul",[v("li",[_._v("判断两张人脸是否属于同一个人、性别预测等属于分类问题，年龄预测、股票走势预测是回归问题。")]),_._v(" "),v("li",[_._v("分类和回归没有明确的界限，比如年龄预测，比如只算到实数，1-100岁，就是多分类问题。")])]),_._v(" "),v("h4",{attrs:{id:"_1-5-1-回归和分类的区别和联系"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-1-回归和分类的区别和联系"}},[_._v("#")]),_._v(" 1.5.1. 回归和分类的区别和联系")]),_._v(" "),v("p",[_._v("区别：分类是推断输入x的"),v("strong",[_._v("离散类别")]),_._v("（如+1，-1）；回归是推断输入x对应的输出值，为"),v("strong",[_._v("连续实数")]),_._v("。")]),_._v(" "),v("p",[_._v("联系：可以利用回归模型进行分类，即"),v("strong",[_._v("将回归模型的输出离散化以进行分类")]),_._v("；也可以利用分类模型进行回归。")]),_._v(" "),v("h3",{attrs:{id:"_1-6-特征提取的重要性"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-特征提取的重要性"}},[_._v("#")]),_._v(" 1.6. 特征提取的重要性")]),_._v(" "),v("p",[v("strong",[_._v("特征提取比机器学习算法重要的多得多")]),_._v("，好的、显著的特征任何算法都有不错的结果，而区别不明显的特征任何算法差别不大。而对于声音、图像等提取特征的方法千差万别，针对测井曲线也是一样。")])])}),[],!1,null,null,null);v.default=r.exports}}]);