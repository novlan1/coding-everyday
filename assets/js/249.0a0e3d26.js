(window.webpackJsonp=window.webpackJsonp||[]).push([[249],{518:function(_,t,v){"use strict";v.r(t);var a=v(14),r=Object(a.a)({},(function(){var _=this,t=_._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[t("ul",[t("li",[t("a",{attrs:{href:"#1-%E5%A4%A7%E8%AF%8D%E6%B1%87%E9%87%8F%E8%BF%9E%E7%BB%AD%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB-lvcsr"}},[_._v("1. 大词汇量连续语音识别 (LVCSR)")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#11-lvcsr%E6%A6%82%E8%BF%B0"}},[_._v("1.1. LVCSR概述")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#12-%E6%AF%8F%E4%B8%80%E4%B8%AAhmm%E6%A8%A1%E5%9E%8B%E6%89%80%E8%A1%A8%E8%BE%BE%E7%9A%84%E5%8D%95%E8%AF%8D%E6%98%AF%E4%BB%80%E4%B9%88"}},[_._v("1.2. 每一个HMM模型所表达的“单词”是什么？")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#13-%E5%A6%82%E4%BD%95%E5%AF%B9%E5%A3%B0%E9%9F%B3%E6%96%87%E4%BB%B6%E5%81%9A%E6%97%B6%E9%97%B4%E8%BD%B4%E7%9A%84%E5%88%92%E5%88%86%E5%B9%B6%E6%90%9C%E7%B4%A2%E6%9C%80%E4%BD%B3%E5%8D%95%E8%AF%8D%E7%BB%84%E5%90%88"}},[_._v("1.3. 如何对声音文件做时间轴的划分并搜索最佳“单词”组合？")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#14-viterbi%E6%90%9C%E7%B4%A2%E7%9A%84%E4%B8%80%E7%A7%8D-two-level-dynamic-programming"}},[_._v("1.4. VITERBI搜索的一种： Two-Level Dynamic Programming")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#15-%E5%A6%82%E4%BD%95%E6%9E%84%E9%80%A0%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"}},[_._v("1.5. 如何构造语言模型？")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#16-%E7%BB%93%E5%90%88%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB"}},[_._v("1.6. 结合深度网络模型的语音识别")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"#161-dnn-hmm-%E4%B8%8E-gmm-hmm%E5%AF%B9%E6%AF%94"}},[_._v("1.6.1. DNN-HMM 与 GMM-HMM对比")])]),_._v(" "),t("li",[t("a",{attrs:{href:"#162-dnn-hmm-%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC"}},[_._v("1.6.2. DNN-HMM 理论推导")])])])])])])]),_._v(" "),t("h2",{attrs:{id:"_1-大词汇量连续语音识别-lvcsr"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-大词汇量连续语音识别-lvcsr"}},[_._v("#")]),_._v(" 1. 大词汇量连续语音识别 (LVCSR)")]),_._v(" "),t("h3",{attrs:{id:"_1-1-lvcsr概述"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-lvcsr概述"}},[_._v("#")]),_._v(" 1.1. LVCSR概述")]),_._v(" "),t("p",[_._v("大词汇量连续语音识别 （Large-scale Vocabulary Continuous Speech Recognition, LVCSR）")]),_._v(" "),t("ul",[t("li",[_._v("问题1. "),t("strong",[_._v("每一个HMM模型所表达的“单词”是什么？")])]),_._v(" "),t("li",[_._v("问题2. 在识别流程中"),t("strong",[_._v("如何对测试声音文件做时间轴的划分")]),_._v("，使每一个分段（SEGMENT）对应一个“单词”？")]),_._v(" "),t("li",[_._v("问题3. "),t("strong",[_._v("如何搜索最佳的“单词”组合？")])]),_._v(" "),t("li",[_._v("问题4. "),t("strong",[_._v("如何构造语言模型 (Language Model)?")])])]),_._v(" "),t("p",[t("strong",[_._v("大词汇量，就是想说什么就说什么")]),_._v("。\n"),t("strong",[_._v("连续语音，就是想怎么说就怎么说，想说多长就说多长")]),_._v("。")]),_._v(" "),t("h3",{attrs:{id:"_1-2-每一个hmm模型所表达的-单词-是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-每一个hmm模型所表达的-单词-是什么"}},[_._v("#")]),_._v(" 1.2. 每一个HMM模型所表达的“单词”是什么？")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609150239_d15a0e092ca4.png",alt:"img"}})]),_._v(" "),t("p",[_._v("三连音（Triphone）示意图")]),_._v(" "),t("p",[_._v("英语中有效的Triphone个数大致在55000左右（过多，需要简化！）")]),_._v(" "),t("p",[_._v("三连音，就是about、above这种建的是同一个模型。")]),_._v(" "),t("p",[t("strong",[_._v("不仅单词内要建模，单词间也要建模")]),_._v("。也就是把所有的三连音穷举一遍。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609150501_de7405877aec.png",alt:"img"}})]),_._v(" "),t("p",[_._v("上图为多个Triphone 合并（Tying）")]),_._v(" "),t("p",[t("strong",[_._v("每个三连音模型是5个状态，silence=>三连音=>silence")])]),_._v(" "),t("p",[_._v("多个triphone联合的训练，降低了triphone的数量。同时在单个triphone里，也把共同的状态联合起来增加它的数据。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609150706_49c82fdb76a0.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("为了建模的方便，把相似的合到了一起，比如wiy和riy")]),_._v("。"),t("strong",[_._v("识别的时候是根据上下文拆开。")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609150730_8b9c1a9b508d.png",alt:"img"}})]),_._v(" "),t("p",[_._v("上图为多个Triphone 联合训练（Tying）")]),_._v(" "),t("p",[t("strong",[_._v("语言模型：猜上下文的词，比如说了一个“我”，接下来说啥")]),_._v("。")]),_._v(" "),t("p",[t("strong",[_._v("汉语中Triphone个数：音节内270多个，音节间3800多个")]),_._v("，这是包含声调后的结果 。这就意味着，"),t("strong",[_._v("汉语构造声学模型比英语更容易")]),_._v("。")]),_._v(" "),t("h3",{attrs:{id:"_1-3-如何对声音文件做时间轴的划分并搜索最佳-单词-组合"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-如何对声音文件做时间轴的划分并搜索最佳-单词-组合"}},[_._v("#")]),_._v(" 1.3. 如何对声音文件做时间轴的划分并搜索最佳“单词”组合？")]),_._v(" "),t("p",[t("strong",[_._v("这是一个搜索问题，搜索就是在由语句构成的空间中，寻找最优句子的过程")]),_._v("，也就是利用已掌握的声学知识、语音学知识、语言模型及语法语义知识等，在状态（指词组、词、HMM的状态）空间中找到最优的状态序列。")]),_._v(" "),t("p",[_._v("搜索方法有很多种，这里归纳如下：")]),_._v(" "),t("ol",[t("li",[_._v("VITERBI搜索 （有多种形式）")]),_._v(" "),t("li",[_._v("A*搜索")]),_._v(" "),t("li",[_._v("随机搜索")])]),_._v(" "),t("p",[_._v("语音：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609151120_1d3fc2b0a56a.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("待求变量：L, 所有t, 所有w。")])]),_._v(" "),t("h3",{attrs:{id:"_1-4-viterbi搜索的一种-two-level-dynamic-programming"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-viterbi搜索的一种-two-level-dynamic-programming"}},[_._v("#")]),_._v(" 1.4. VITERBI搜索的一种： Two-Level Dynamic Programming")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609151433_aa0962287c24.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("英语里V有10000个左右")])]),_._v(" "),t("p",[t("strong",[_._v("起始位置是0、终止于e、有"),t("em",[_._v("l")]),_._v("个单词的最佳匹配")]),_._v("，等于，"),t("strong",[_._v("终止于b-1、有"),t("em",[_._v("l-1")]),_._v("个单词，加上，b到e、有1个单词")])]),_._v(" "),t("p",[t("strong",[t("em",[_._v("l")]),_._v("有上界，就是固定时间内说的triphone数量有限")]),_._v("。")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609151611_bb8a71b24f19.png",alt:"img"}})]),_._v(" "),t("h3",{attrs:{id:"_1-5-如何构造语言模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-如何构造语言模型"}},[_._v("#")]),_._v(" 1.5. 如何构造语言模型？")]),_._v(" "),t("p",[t("strong",[_._v("定义 （N-gram）: 一个单词出现的概率，只与它前面的N个单词相关。")])]),_._v(" "),t("p",[_._v("P(w1, w2, w3, … , wn)=P(w1)P(w2|w1)P(w3|w1w2)P(w4|w1w2w3)…P(wn|w1w2…wn-1)")]),_._v(" "),t("p",[_._v("（1）在1-gram模型下")]),_._v(" "),t("p",[_._v("P(w1, w2, w3, … , wn)=P(w1)P(w2|w1)P(w3|w1w2)P(w4|w1w2w3)…P(wn|w1w2…wn-1)")]),_._v(" "),t("p",[_._v("≈P(w1)P(w2|w1)P(w3|w2)P(w4|w3)…P(wn|wn-1)")]),_._v(" "),t("p",[_._v("（2）在2-gram模型下：")]),_._v(" "),t("p",[_._v("P(w1, w2, w3, … , wn)=P(w1)P(w2|w1)P(w3|w1w2)P(w4|w1w2w3)…P(wn|w1w2…wn-1)")]),_._v(" "),t("p",[_._v("≈P(w1)P(w2|w1)P(w3|w1w2)P(w4|w2w3)…P(wn|wn-2wn-1)")]),_._v(" "),t("p",[_._v("（3）在3-gram模型下：")]),_._v(" "),t("p",[_._v("P(w1, w2, w3, … , wn)=P(w1)P(w2|w1)P(w3|w1w2)P(w4|w1w2w3)…P(wn|w1w2…wn-1)")]),_._v(" "),t("p",[_._v("≈P(w1)P(w2|w1)P(w3|w1w2)P(w4|w1w2w3)…P(wn|wn-3wn-2wn-1)")]),_._v(" "),t("p",[t("strong",[_._v("在N-Gram 中， N越大，模型越复杂，对训练样本需求越多")]),_._v("。当然，样本足够情况下，"),t("strong",[_._v("N越大，训练后效果会更好")]),_._v("。因此需要选一个合适的N来平衡准确度与样本数量要求。")]),_._v(" "),t("p",[t("strong",[_._v("一般来说，英语N=3, 汉语N=4")]),_._v("。")]),_._v(" "),t("p",[t("strong",[_._v("N-gram用文本训练就可以")]),_._v("，不需要用语音。")]),_._v(" "),t("h3",{attrs:{id:"_1-6-结合深度网络模型的语音识别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-结合深度网络模型的语音识别"}},[_._v("#")]),_._v(" 1.6. 结合深度网络模型的语音识别")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609153401_20b3d5307a14.png",alt:"img"}})]),_._v(" "),t("p",[t("strong",[_._v("DNN-HMM模型框架")])]),_._v(" "),t("h4",{attrs:{id:"_1-6-1-dnn-hmm-与-gmm-hmm对比"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-1-dnn-hmm-与-gmm-hmm对比"}},[_._v("#")]),_._v(" 1.6.1. DNN-HMM 与 GMM-HMM对比")]),_._v(" "),t("p",[_._v("假设输入语音为{x_1,x_2,…,x_T}，且HMM有N个状态。")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("GMM-HMM (Gaussian Mixture Models-Hidden Markov Models) 是用"),t("strong",[_._v("GMM")]),_._v("来模拟概率密度函数"),t("strong",[_._v("p(xt|si),")]),_._v(" 其中i=1,2,…,N。")])]),_._v(" "),t("li",[t("p",[_._v("DNN-HMM (Deep Neural Networks-Hidden Markov Models ) 是用"),t("strong",[_._v("DNN")]),_._v("来模拟概率密度函数"),t("strong",[_._v("p(si|xt)")]),_._v("，其中i=1,2,…,N")])])]),_._v(" "),t("p",[_._v("GMM-HMM模拟的是bjo")]),_._v(" "),t("h4",{attrs:{id:"_1-6-2-dnn-hmm-理论推导"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-2-dnn-hmm-理论推导"}},[_._v("#")]),_._v(" 1.6.2. DNN-HMM 理论推导")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609153634_6ec8884fc1df.png",alt:"img"}})]),_._v(" "),t("p",[_._v("由于p(xt)对不同的HMM模型都不变，在识别过程中可以忽略，因此我们可以简化如下：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609153706_06992e35bcd5.png",alt:"img"}})]),_._v(" "),t("p",[_._v("在识别中，某段语音属于某个“单词”w 是这样判断的：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609153754_6b60a73bed8c.png",alt:"img"}})]),_._v(" "),t("p",[_._v("其中p(w)表示某个“单词”w 出现的先验概率，可以通过统计获得。而")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609153826_b3a25e0148d7.png",alt:"img"}})]),_._v(" "),t("p",[_._v("最终决策过程：")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609153925_e0dcda035bff.png",alt:"img"}})]),_._v(" "),t("p",[_._v("问题："),t("strong",[_._v("如何获得π(q0), aq"),t("sub",[_._v("t−1")]),_._v("q"),t("sub",[_._v("t")]),_._v(", p(qt)和p(qt|xt)?")])]),_._v(" "),t("p",[_._v("回答：首先训练一个GMM-HMM模型，"),t("strong",[_._v("由GMM-HMM模型获得π(q0), aqt−1qt")]),_._v("。 通过"),t("strong",[_._v("GMM-HMM预测每个xt的标签qt，统计获得p(qt)")]),_._v("。最后用深度网络获得p(qt|xt)。")]),_._v(" "),t("blockquote",[t("p",[_._v("Dong Yu and Li Deng, Automatic Speech Recognition: A Deep Learning Approach, Springer, 2014. (Chapter 6)")])]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609154406_e8f11c098cfa.png",alt:"img"}})]),_._v(" "),t("p",[_._v("上图为算法流程")]),_._v(" "),t("p",[_._v("实验结果 （9层神经网络，用自编码器初始化）")]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609154517_703e9e9f98cf.png",alt:"img"}})]),_._v(" "),t("p",[t("img",{attrs:{src:"http://img.uwayfly.com/article_mike_20200609154529_305244c7537e.png",alt:"img"}})])])}),[],!1,null,null,null);t.default=r.exports}}]);