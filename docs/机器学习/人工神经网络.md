- [1. 人工神经网络](#1-人工神经网络)
  - [神经元模型和感知器算法](#神经元模型和感知器算法)
  - [1.1. 感知器算法证明](#11-感知器算法证明)
  - [1.2. 人工智能的第一次冬天](#12-人工智能的第一次冬天)
  - [1.3. 多层神经网络](#13-多层神经网络)
  - [1.6. 后向传播算法（Back Propogation Algorithm）](#16-后向传播算法back-propogation-algorithm)
  - [1.7. BP算法推导](#17-bp算法推导)
  - [1.8. BP一般性推导](#18-bp一般性推导)
  - [1.10. 多层神经网络的优劣势](#110-多层神经网络的优劣势)
  - [1.11. 随机梯度下降](#111-随机梯度下降)
  - [1.12. 训练数据初始化](#112-训练数据初始化)
  - [1.13. (W, b)的初始化](#113-w-b的初始化)
  - [1.14. Batch Normalization](#114-batch-normalization)
  - [1.15. 目标函数选择](#115-目标函数选择)
  - [1.16. 参数更新策略](#116-参数更新策略)
    - [1.16.1. 常规的更新 （Vanilla Stochastic Gradient Descent）](#1161-常规的更新-vanilla-stochastic-gradient-descent)
  - [1.17. 训练建议](#117-训练建议)
  

## 1. 人工神经网络

### 神经元模型和感知器算法

![img](http://img.uwayfly.com/article_mike_20200530121045_cd977e06b33f.png)


感知器算法和SVM的本质区别：**感知器算法是思路是一个一个样本的看，如果对就不管它，如果不对更新W和b**，SVM的思路是将样本集视为整体。
感知器很像我们日常生活，**比如考试经常考第一，就不去调整，如果语文没考好，就要调整学习语文的方法**。SVM算法是全局，**感知器算法是针对每一个个体去调整**。



1957年，Frank Rosenblatt从纯数学的度重新考察这一模型，指出能够从一些输入输出对(X, y)中通过学习算法获得权重W和b。

![img](http://img.uwayfly.com/article_mike_20200530113822_84a41975b152.png)



算法本质是：

![img](http://img.uwayfly.com/article_mike_20200530113753_faf1b98fea05.png)





### 1.1. 感知器算法证明



![img](http://img.uwayfly.com/article_mike_20200530115752_7e648f0dbd1e.png)





那么原来的算法可以改成：

![img](http://img.uwayfly.com/article_mike_20200530120223_3dee4390e05a.png)



![img](http://img.uwayfly.com/article_mike_20200530115813_b1f73645a336.png)



![img](http://img.uwayfly.com/article_mike_20200530120557_dcd9607ad399.png)



![img](http://img.uwayfly.com/article_mike_20200530120641_457faca9ff1b.png)





### 1.2. 人工智能的第一次冬天

Minsky第一次提出了线性可分（不可分）的概念。1969年《Perceptron》。日常生活中有很多分类问题是非线性可分的。

![img](http://img.uwayfly.com/article_mike_20200530122245_47e7de087bdb.png)



![img](http://img.uwayfly.com/article_mike_20200530122726_b7a9f5da8e2c.png)



这本书的出现，使人们意识到感知器的算法是如此狭窄，使得人工智能项目的经费都批不下来。十年左右的停滞。





### 1.3. 多层神经网络

第二次复兴：**用非线性的函数集合（模型）去区分非线性的样本**

![img](http://img.uwayfly.com/article_mike_20200530155101_6916b1b885b7.png)



**φ(*)是非线性函数**，因为若不是的话，和上面的单层网络没有任何区别。

定理：**当φ(*)为阶跃函数时，三层网络可以模拟任意决策面**。

![img](http://img.uwayfly.com/article_mike_20200530155434_9a36491cdce8.png)



**阶跃函数就是大于0的地方等于1，让小于0的地方等于1**。

举例：两层神经网络模拟一个非线性决策面，最后**W取[1,1,1], b取-2.5**：

![img](http://img.uwayfly.com/article_mike_20200530160204_1eec8e098901.png)



如果决策面是四边形，第二层神经元就有4个，最后**W取[1,1,1,1], b取-3.5**。

如果决策面是圆的话，第二层就有**无穷多个神经元，去逼近圆**。

![img](http://img.uwayfly.com/article_mike_20200530161130_c3d472f9647a.png)



如果决策面分开了，**要在第二层里把神经元竖着写下去**，并且加一层神经元，把他们的结果合并起来。

对于两个三角形的情况，最后**W取[1,1], b取-0.5**。只要有一个1，最后结果就是1；都是0，最后结果就是0。

![img](http://img.uwayfly.com/article_mike_20200530161033_29588e9d48ca.png)





神经网络理论并不完备，对于某类问题适合什么样的模型并没有答案，只能用实验的方法。


### 1.6. 后向传播算法（Back Propogation Algorithm）

梯度下降法求局部极值（Gradient Descent Method）。

![img](http://img.uwayfly.com/article_mike_20200530164030_1f323ed65992.png)



![img](http://img.uwayfly.com/article_mike_20200530164235_105f1386509b.png)



中间的式子中，α大于0，所以f(wk+1) <f(wk)

- 梯度下降法就是不断试探的过程。
- 和初始值的选择有很大的关系。

先找到一个下降的方向，然后再想具体怎么走。所以梯度下降法有很多变种。**梯度下降法只负责找一个方向**。



### 1.7. BP算法推导



先从一个简化版本入手：



![img](http://img.uwayfly.com/article_mike_20200530173143_1de34e810355.png)



![img](http://img.uwayfly.com/article_mike_20200530173201_57aca6c31bec.png)

和上面公式的不同是，上面是一维的，用d，这里是多维的，所以用偏导。

每输入一个X，求一次W和b，直到全部输完。

**先算y、a1、a2的偏导，因为这三个点连接关系最丰富**。

![img](http://img.uwayfly.com/article_mike_20200530173410_bde402118272.png)



![img](http://img.uwayfly.com/article_mike_20200530173841_cf87002b5654.png)



为什么叫后向传播算法？输入一个X，首先进行前向计算，得到y、z、a等，然后计算偏导，**计算偏导的时候是从后面算到前面**，即y、a1、a2直到w等。





常见的非线性函数：



![img](http://img.uwayfly.com/article_mike_20200530172814_a687d84443fc.png)



![img](http://img.uwayfly.com/article_mike_20200530172839_7a5570efd646.png)



要让后向传播算法能够进行，必须**改造φ(x)**，因为阶跃函数的φ'(x)在除了x=0的时候都等于0，这显然不合适。比如改造成**sigmod函数**。**`φ'(x) = φ(x)*(1-φ(x))`**

**将sigmoid函数或者tanh函数替换阶跃函数，也能用三层网络模拟任何决策面**。

sigmoid函数和tanh函数的问题在于，**当x特别大的时候，y被压制了，导致信息无法从这一层传导到下一层。而Relu函数可以**。第四种被称为**Leak Relu**函数，**当x < 0时，用较小的斜率压缩，而不是都将其变为0**.


### 1.8. BP一般性推导

![img](http://img.uwayfly.com/article_mike_20200530220509_7adbb9a23fd3.png)



BP流程：

![img](http://img.uwayfly.com/article_mike_20200530220542_ac4f00e62f33.png)



**某一层W是m*n，就是m个神经元，b和z的维度都是m，和神经元个数一致**。

求偏E/偏Zi，需要先求偏E/偏ai，然后乘以偏ai/偏Zi，因为Zi并不和E直接相连，它们通过ai连接。





![img](http://img.uwayfly.com/article_mike_20200530222525_33403d4d2e2b.png)



![img](http://img.uwayfly.com/article_mike_20200530222547_e42de5825331.png)



i，j容易混淆，就是定义W的时候[[w11, w12, w13, ...], [w21, w22, w23], ...]


### 1.10. 多层神经网络的优劣势

优势：

1. **基本单元简单，多个基本单元可扩展为非常复杂的非线性函数。因此易于构建，同时模型有很强的表达能力**。
2. 训练和测试的计算并行性非常好，有利于在**分布式系统**上的应用。
3. **模型构建来源于对人脑的仿生，话题丰富**，各种领域的研究人员都有兴趣，都能做贡献。



劣势：

1. 数学不漂亮，**优化算法只能获得局部极值，算法性能与初始值有关**。
2. **不可解释。训练神经网络获得的参数与实际任务的关联性非常模糊**。
3. **模型可调整的参数很多** （网络层数、每层神经元个数、非线性函数、学习率、优化方法、终止条件等等），使得训练神经网络变成了一门“艺术”。
4. 如果要训练相对复杂的网络，需要**大量的训练样本**。



### 1.11. 随机梯度下降

1. （**不用每输入一个样本就去变换参数，而是输入一批样本**（叫做一个`BATCH`或`MINI-BATCH`），**求出这些样本的梯度平均值后，根据这个平均值改变参数**。
2. 在神经网络训练中，BATCH的样本数大致设置为50-200不等。

随机梯度下降的好处，**降低随机性**，同时**不要让参数进行太剧烈的变化，即通过平均值改变，可以降低噪声的影响**。





### 1.12. 训练数据初始化

做均值和方差归一化。目的：**使输入的特征每一个维度对后面的影响都差不多。**





### 1.13. (W, b)的初始化

**梯度消失**现象：如**果W<sup>T</sup>+b一开始很大或很小，那么梯度将趋近于0**，反向传播后前面与之相关的梯度也趋近于0，导致**训练缓慢**。 因此，我们要使y=±1一开始在零附近。

W和b的初始化问题，最近很火，有很多相关文章

![img](http://img.uwayfly.com/article_mike_20200530232832_ab3a49394bff.png)





### 1.14. Batch Normalization

google论文：Batch normalization accelerating deep network training by reducing internal covariate shift (2015)

基本思想：**既然我们希望每一层获得的值都在0附近，从而避免梯度消失现象，那么我们为什么不直接把每一层的值做基于均值和方差的归一化呢**？

![img](http://img.uwayfly.com/article_mike_20200530234729_c3e58bada0db.png)

batch normalization中的均值和方差，是在不断输入样本中累积和记录的。

![img](http://img.uwayfly.com/article_mike_20200530234816_a01ffe74d06b.png)

和上面一样，**值不能都集中在0附近，否则就变成了线性模型，没有充分利用其非线性的性质，以至于分类效果不佳**。因此不能就只是归一化这样结束，**还要用β和γ，将它放缩掉。β和γ作为训练的参数**。


### 1.15. 目标函数选择

1、加关于W的正则，原因：W不应该很大，否则输入输出会很大，从而不可控。

![img](http://img.uwayfly.com/article_mike_20200530235007_18e3f9c0568b.png)



2、如果是分类问题，F(W)可以采用SOFTMAX函数和交叉熵的组合。

![img](http://img.uwayfly.com/article_mike_20200531095021_74cc3f775da8.png)



如果F(W)是SOFTMAX函数和交叉熵的组合，那么求导将会有非常简单的形式：

![img](http://img.uwayfly.com/article_mike_20200531095106_ed1e9a66b9b0.png)



最后输出的时候，**强行用softmax变成概率**。比如**猫狗分类问题，有可能有个样本60%像猫，40%像狗**。softmax在图像识别中特别常见。

交叉熵中，可以通过Jensen不等式证明，**如果所有的p和为1，所有的q和为1，那么E一定大于0**。并且**如果q和p越像，那么E越小**。

之前求E的方法，称为`Mean Squared Error` (均方误差)

### 1.16. 参数更新策略

#### 1.16.1. 常规的更新 （Vanilla Stochastic Gradient Descent）

```
nn.W{k} = nn.W{k} - nn.learning_rate*nn.W_grad{k};
nn.b{k} = nn.b{k} - nn.learning_rate*nn.b_grad{k};
```

SGD的问题

（1）(W,b)的**每一个分量获得的梯度绝对值有大有小**，一些情况下，**将会迫使优化路径变成Z字形状**。

![img](http://img.uwayfly.com/article_mike_20200531102515_214c497dfaa1.png)



上图中的线可视为等高线，E相等的线，一个方向gradient很大，另一个方向很小。梯度的分量有的特别大，有的特别小的时候，优化的路径不是特别好。



（2）SGD求梯度的策略过于随机，**由于上一次和下一次用的是完全不同的BATCH数据，将会出现优化的方向随机的情况**。

![img](http://img.uwayfly.com/article_mike_20200531102633_f379d94bb278.png)



解决各个方向梯度不一致的方法：

**（1）AdaGrad**

![img](http://img.uwayfly.com/article_mike_20200531102802_d74d3f179edc.png)



AdaGrad：**如果某一个方向上的梯度的绝对值特别大或特别小，就除以这个梯度的绝对值**，使得梯度绝对值高的步长不要太大，梯度绝对值低的步长不要太小。

不仅如此，**它不只算了某一个batch里的梯度，还做了叠加。从而越到后面梯度和r越来越大，步长越来越小，而开始时很大**。



**（2）RMSProp**

![img](http://img.uwayfly.com/article_mike_20200531102917_7cc247594f30.png)



RMSProp：**给以前的累积梯度r和现在的梯度加一个权重ρ，二者权重之和为1，之前等于是各0.5**。用此权重平衡更看重谁。



**（3）Momentum**

![img](http://img.uwayfly.com/article_mike_20200531103038_b7a9a641c013.png)



Momentum：**第一次算出来的方向对第二次还有一点点影响**。



**（4）Adam**

![img](http://img.uwayfly.com/article_mike_20200531103222_5373fce65c07.png)



Adam：综合以上方法，让**梯度各个方向差不多，同时让梯度下降方向相对平滑**。**ρ1：0.9，ρ2：0.999**。结果证明并不好用。





### 1.17. 训练建议

1. 一般情况下，在训练集上的目标函数的平均值（cost，就是上面提到的E）会随着训练的深入而不断减小，如果这个指标有增大情况，停下来。有两种情况：**第一是采用的模型不够复杂，以致于不能在训练集上完全拟合；第二是已经训练很好了**。
2. **分出一些验证集（Validation Set）**,训练的本质目标是在验证集上获取最大的识别率。因此训练一段时间后，必须在验证集上测试识别率，保存使验证集上识别率最大的模型参数，作为最后结果。
3. 注意**调整学习率（Learning Rate）**,**如果刚训练几步cost就增加，一般来说是学习率太高了；如果每次cost变化很小，说明学习率太低。**
4. **Batch Normalization** 比较好用，用了这个后，对学习率、参数更新策略等不敏感。建议如果用Batch Normalization, 更新策略用最简单的SGD即可，我的经验是加上其他反而不好。
5. 如果不用Batch Normalization, 我的经验是，合理变换其他参数组合，也可以达到目的。
6. 由于梯度累积效应，**AdaGrad, RMSProp, Adam**三种更新策略**到了训练的后期会很慢**，可以采用提高学习率的策略来补偿这一效应。

第二条的原因是：**过拟合，尽信书不如无书**。**在训练集上效果很好，但在测试集上效果不好，就是书呆子**。

要调的最重要的一个参数是学习率。